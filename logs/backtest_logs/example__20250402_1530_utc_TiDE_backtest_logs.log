2025-04-02 15:30:53 UTC - matplotlib - wrapper - DEBUG - matplotlib data path: /home/vscode/.local/lib/python3.11/site-packages/matplotlib/mpl-data
2025-04-02 15:30:53 UTC - matplotlib - wrapper - DEBUG - CONFIGDIR=/home/vscode/.config/matplotlib
2025-04-02 15:30:53 UTC - matplotlib - <module> - DEBUG - interactive is False
2025-04-02 15:30:53 UTC - matplotlib - <module> - DEBUG - platform is linux
2025-04-02 15:30:53 UTC - matplotlib - wrapper - DEBUG - CACHEDIR=/home/vscode/.cache/matplotlib
2025-04-02 15:30:53 UTC - matplotlib.font_manager - _load_fontmanager - DEBUG - Using fontManager instance from /home/vscode/.cache/matplotlib/fontlist-v390.json
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.backend.piping.pipe(['renderer', 'formatter', 'neato_no_op', 'quiet'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.backend.rendering.render(['renderer', 'formatter', 'neato_no_op', 'quiet'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.backend.unflattening.unflatten(['stagger', 'fanout', 'chain', 'encoding'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.backend.viewing.view(['quiet'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.quoting.quote(['is_html_string', 'is_valid_id', 'dot_keywords', 'endswith_odd_number_of_backslashes', 'escape_unescaped_quotes'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.quoting.a_list(['kwargs', 'attributes'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.quoting.attr_list(['kwargs', 'attributes'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.dot.Dot.clear(['keep_attrs'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.dot.Dot.__iter__(['subgraph'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.dot.Dot.node(['_attributes'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.dot.Dot.edge(['_attributes'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.dot.Dot.attr(['_attributes'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.dot.Dot.subgraph(['name', 'comment', 'graph_attr', 'node_attr', 'edge_attr', 'body'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.piping.Pipe._pipe_legacy(['renderer', 'formatter', 'neato_no_op', 'quiet'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.saving.Save.save(['directory'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.rendering.Render.render(['directory', 'view', 'cleanup', 'format', 'renderer', 'formatter', 'neato_no_op', 'quiet', 'quiet_view'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.rendering.Render.view(['directory', 'cleanup', 'quiet', 'quiet_view'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.unflattening.Unflatten.unflatten(['stagger', 'fanout', 'chain'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.graphs.BaseGraph.__init__(['comment', 'filename', 'directory', 'format', 'engine', 'encoding', 'graph_attr', 'node_attr', 'edge_attr', 'body', 'strict'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.sources.Source.from_file(['directory', 'format', 'engine', 'encoding', 'renderer', 'formatter'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.sources.Source.__init__(['filename', 'directory', 'format', 'engine', 'encoding'])
2025-04-02 15:30:54 UTC - graphviz._tools - decorator - DEBUG - deprecate positional args: graphviz.sources.Source.save(['directory'])
2025-04-02 15:30:54 UTC - matplotlib.pyplot - switch_backend - DEBUG - Loaded backend tkagg version 8.6.
2025-04-02 15:30:55 UTC - src.pipelines.dl_full_pipeline - main - INFO - >>>>> Starting deep learning pipeline execution for TiDE_multivariate model
2025-04-02 15:30:55 UTC - src.pipelines.dl_full_pipeline - main - DEBUG - General Configuration dictionary:
{'backtest_results_save_path': None,
 'backtest_retraining_frequency': 3,
 'backtest_start_date': None,
 'backtest_timestamp': '20250402_1530',
 'backtest_windows': 6,
 'close_optuna_dashboard': False,
 'close_tensorboard': False,
 'covariates_path': '/workspace/anonymization_data/data_for_run/anonymized_covariates_mv.parquet',
 'data_format': 'multivariate',
 'data_path': '/workspace/anonymization_data/data_for_run/anonymized_processed_data.parquet',
 'model_class': <class 'darts.models.forecasting.tide_model.TiDEModel'>,
 'model_name': 'TiDE_multivariate',
 'open_optuna_dashboard': True,
 'open_tensorboard': True,
 'optuna_direction': 'minimize',
 'optuna_retraining_frequency': False,
 'optuna_start_date': None,
 'optuna_storage_path': None,
 'optuna_study_name': 'TiDE_multivariate_utc_20250402_1530',
 'optuna_timeout': 10800,
 'optuna_windows': 3,
 'output_chunk_length': 3,
 'output_chunk_shift': 1,
 'prediction_length': 3,
 'pruner_class': <class 'optuna.pruners._median.MedianPruner'>,
 'pruner_kwargs': None,
 'random_state': 1000,
 'run_backtest': True,
 'run_optuna': True,
 'sampler_class': <class 'optuna.samplers._tpe.sampler.TPESampler'>,
 'sampler_kwargs': None,
 'scaler': MinMaxScaler(),
 'study_name': None,
 'tensorboard_id': 'TiDE_multivariate_utc_20250402_1530',
 'tensorboard_path_backtest': None,
 'tensorboard_path_optuna': None,
 'trial_rank': 0,
 'use_future_covariates': True,
 'use_modelcheckpoint_callback': False,
 'use_past_covariates': True,
 'use_static_covariates': True,
 'use_validation_set': True}
2025-04-02 15:30:55 UTC - src.pipelines.dl_full_pipeline - main - DEBUG - Model configuration dictionary:
{'base_params': {'force_reset': True,
                 'input_chunk_length': 12,
                 'output_chunk_length': 3,
                 'output_chunk_shift': 1,
                 'random_state': 1000,
                 'use_static_covariates': True},
 'early_stopping_kwargs': {'min_delta': 0.0005, 'patience': 15},
 'lr_scheduler_params': {'lr_scheduler_cls': <class 'torch.optim.lr_scheduler.OneCycleLR'>,
                         'lr_scheduler_kwargs': {'div_factor': 40,
                                                 'final_div_factor': 75,
                                                 'frequency': 1,
                                                 'interval': 'step',
                                                 'max_lr': 0.0001,
                                                 'pct_start': 0.2,
                                                 'three_phase': True,
                                                 'total_steps': 12601}},
 'model_architecture_params': {'decoder_output_dim': 16,
                               'dropout': 0.1,
                               'hidden_size': 128,
                               'num_decoder_layers': 1,
                               'num_encoder_layers': 1,
                               'temporal_decoder_hidden': 16,
                               'temporal_width_future': 4,
                               'temporal_width_past': 4,
                               'use_layer_norm': True,
                               'use_reversible_instance_norm': True},
 'model_checkpoint_kwargs': {'every_n_epochs': 15,
                             'save_last': False,
                             'save_top_k': 1},
 'trainer_params': {'accelerator': 'gpu',
                    'batch_size': 256,
                    'enable_checkpointing': False,
                    'enable_model_summary': True,
                    'enable_progress_bar': True,
                    'gradient_clip_algorithm': 'norm',
                    'gradient_clip_val': 10,
                    'log_every_n_steps': 10,
                    'n_epochs': 300,
                    'optimizer_cls': <class 'torch.optim.adamw.AdamW'>,
                    'weight_decay': 0.005}}
2025-04-02 15:30:55 UTC - src.pipelines.dl_full_pipeline - main - DEBUG - Parameter search space:
{'batch_size': {'type': 'categorical', 'values': [4, 8, 16]},
 'decoder_output_dim': {'type': 'categorical', 'values': [16, 32, 64]},
 'div_factor': {'type': 'categorical', 'values': [25, 30, 35, 40, 45, 50]},
 'dropout': {'high': 0.7, 'low': 0.05, 'type': 'float'},
 'final_div_factor': {'type': 'categorical', 'values': [75, 100, 250, 500]},
 'gradient_clip_val': {'high': 100.0, 'log': True, 'low': 0.3, 'type': 'float'},
 'hidden_size': {'type': 'categorical', 'values': [128, 256, 512]},
 'input_chunk_length': {'type': 'categorical', 'values': [3, 6, 9, 12]},
 'max_lr': {'high': 0.001, 'log': True, 'low': 5e-07, 'type': 'float'},
 'num_decoder_layers': {'high': 3, 'low': 1, 'type': 'int'},
 'num_encoder_layers': {'high': 3, 'low': 1, 'type': 'int'},
 'pct_start': {'type': 'categorical', 'values': [0.2, 0.25, 0.3, 0.35]},
 'temporal_decoder_hidden': {'type': 'categorical', 'values': [8, 16, 32, 64]},
 'three_phase': {'type': 'categorical', 'values': [True, False]},
 'weight_decay': {'high': 0.1, 'log': True, 'low': 5e-05, 'type': 'float'}}
2025-04-02 15:30:55 UTC - src.utilities.general_utils - startup - DEBUG - Initializing random seed and dashboards
2025-04-02 15:30:55 UTC - src.utilities.general_utils - set_all_seeds - INFO - Setting random seed to 1000
2025-04-02 15:30:55 UTC - src.utilities.general_utils - start_dashboard - INFO - tensorboard is already running on port 6006 (PID: 7332). Skipping new launch.
2025-04-02 15:30:55 UTC - src.utilities.general_utils - start_dashboard - INFO - optuna is already running on port 8080 (PID: 7490). Skipping new launch.
2025-04-02 15:30:55 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - >>>>>>> Starting data pipeline execution
2025-04-02 15:30:55 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Loaded dataset from /workspace/anonymization_data/data_for_run/anonymized_processed_data.parquet
2025-04-02 15:30:55 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Loaded covariates from /workspace/anonymization_data/data_for_run/anonymized_covariates_mv.parquet
2025-04-02 15:30:55 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Transforming data to Darts TimeSeries Objects
2025-04-02 15:30:55 UTC - src.pipelines.data_pipeline - create_multivariate_timeseries - INFO - Timeseries data format: single Multivariate TimeSeries
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - create_multivariate_timeseries - DEBUG - Darts TimeSeries Objects information from function create_multivariate_timeseries:
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - _log_timeseries_information - INFO - 
Main Series info:
  Data Type: <class 'list'>  -  Length of list: 1    -  Total components across all series: 300
  Element type: <class 'darts.timeseries.TimeSeries'>  -  Format: multivariate
  Start period {Timestamp('2015-01-01 00:00:00')} - End periods in series: {Timestamp('2019-06-01 00:00:00')}
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - _log_timeseries_information - INFO - 
Past Covariates info:
  Data Type: <class 'list'>  -  Length of list: 1    -  Total components across all series: 5
  Element type: <class 'darts.timeseries.TimeSeries'>  -  Format: multivariate
  Start period {Timestamp('2015-01-01 00:00:00')} - End periods in series: {Timestamp('2019-06-01 00:00:00')}
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - _log_timeseries_information - INFO - 
Future Covariates info:
  Data Type: <class 'list'>  -  Length of list: 1    -  Total components across all series: 5
  Element type: <class 'darts.timeseries.TimeSeries'>  -  Format: multivariate
  Start period {Timestamp('2015-01-01 00:00:00')} - End periods in series: {Timestamp('2019-06-01 00:00:00')}
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Creating Backtest datasets. Backtest start base date: 2018-10-01 00:00:00
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - DEBUG - Function split_scale_datasets preparing datasets for 6 window(s), forecast base date=2018-10-01 00:00:00, prediction_length=3, output_chunk_shift=1
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 0 - Base date: 2018-10-01 - Train end date: 2018-06-01 - Validation end date: 2018-09-01 - Forecast period: 2018-11-01 - 2019-01-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 1 - Base date: 2018-11-01 - Train end date: 2018-07-01 - Validation end date: 2018-10-01 - Forecast period: 2018-12-01 - 2019-02-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 2 - Base date: 2018-12-01 - Train end date: 2018-08-01 - Validation end date: 2018-11-01 - Forecast period: 2019-01-01 - 2019-03-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 3 - Base date: 2019-01-01 - Train end date: 2018-09-01 - Validation end date: 2018-12-01 - Forecast period: 2019-02-01 - 2019-04-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 4 - Base date: 2019-02-01 - Train end date: 2018-10-01 - Validation end date: 2019-01-01 - Forecast period: 2019-03-01 - 2019-05-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 5 - Base date: 2019-03-01 - Train end date: 2018-11-01 - Validation end date: 2019-02-01 - Forecast period: 2019-04-01 - 2019-06-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Backtest datasets created. Number of windows: 6
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Creating Optuna datasets. Optuna start base date: 2018-04-01 00:00:00
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - DEBUG - Function split_scale_datasets preparing datasets for 3 window(s), forecast base date=2018-04-01 00:00:00, prediction_length=3, output_chunk_shift=1
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 0 - Base date: 2018-04-01 - Train end date: 2017-12-01 - Validation end date: 2018-03-01 - Forecast period: 2018-05-01 - 2018-07-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 1 - Base date: 2018-05-01 - Train end date: 2018-01-01 - Validation end date: 2018-04-01 - Forecast period: 2018-06-01 - 2018-08-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - split_scale_datasets - INFO - Processing window 2 - Base date: 2018-06-01 - Train end date: 2018-02-01 - Validation end date: 2018-05-01 - Forecast period: 2018-07-01 - 2018-09-01
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Optuna datasets created. Number of windows: 3
2025-04-02 15:30:59 UTC - src.pipelines.data_pipeline - execute_data_pipeline - INFO - Data pipeline completed successfully in 0.1 minutes
2025-04-02 15:30:59 UTC - src.pipelines.dl_optuna - execute_optuna_study - INFO - >>>>>>> Starting Optuna hyperparameter optimization
2025-04-02 15:30:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:30:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:30:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:31:00 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:31:00 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.6254691828474879, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_0_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.35500826756904236, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f24146e90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f241d3c10>]}, optimizer_kwargs={'weight_decay': 0.08723126842250545}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 6.608823990453715e-06, 'pct_start': 0.35, 'div_factor': 45, 'final_div_factor': 500, 'three_phase': False})
2025-04-02 15:31:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:31:00 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 15:31:00 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:31:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:31:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:31:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:31:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:31:00 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 6.2 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
6.3 M     Trainable params
0         Non-trainable params
6.3 M     Total params
25.128    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:31:00 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_0_window_0/hparams.yaml
2025-04-02 15:31:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:31:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:31:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:31:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:31:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.464145
2025-04-02 15:31:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:31:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:31:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:31:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:31:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:31:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.445877
2025-04-02 15:31:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:31:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:31:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:31:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:31:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:31:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.430785
2025-04-02 15:31:41 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:31:41 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:31:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:31:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:31:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=64, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.41789273986989567, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_1_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6510320459909178, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed4d050>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed4ff10>]}, optimizer_kwargs={'weight_decay': 0.0005792700616496243}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 2.9582739357222816e-06, 'pct_start': 0.25, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 15:31:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:31:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:31:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:31:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:31:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:31:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:31:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:31:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 460 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.797   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:31:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_1_window_0/hparams.yaml
2025-04-02 15:32:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.484043
2025-04-02 15:32:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:32:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.480033
2025-04-02 15:32:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:32:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.465191
2025-04-02 15:32:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:32:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:32:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:32:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:32:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.6436604085373561, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_2_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 6.258055633173397, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bf7b10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103bf5790>]}, optimizer_kwargs={'weight_decay': 7.043760402001183e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 1.0239742302840205e-06, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:32:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:32:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:32:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:32:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 13.3 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
13.4 M    Trainable params
0         Non-trainable params
13.4 M    Total params
53.491    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:32:16 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_2_window_0/hparams.yaml
2025-04-02 15:32:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.532114
2025-04-02 15:32:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:32:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.481847
2025-04-02 15:32:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:32:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.48164
2025-04-02 15:32:28 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:32:28 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:32:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:32:28 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:32:28 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.4732925506150042, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_3_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 31.73059592949981, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d79f90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d7ab50>]}, optimizer_kwargs={'weight_decay': 0.00028354876924123446}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 2.5778559687706353e-05, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 15:32:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:32:28 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:32:28 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:32:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:28 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 78.8 K | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.404    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:32:28 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_3_window_0/hparams.yaml
2025-04-02 15:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.36074
2025-04-02 15:32:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:32:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.381638
2025-04-02 15:32:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:32:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.386754
2025-04-02 15:32:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:32:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:32:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:32:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:32:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=2, decoder_output_dim=64, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.3519563261204097, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_4_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5463818764421808, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feef28d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feef2810>]}, optimizer_kwargs={'weight_decay': 0.00011759059432063343}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 0.0001880250625228401, 'pct_start': 0.35, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 15:32:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:32:51 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 15:32:51 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:32:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:32:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:32:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:32:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:32:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 1.2 M  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.240   Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:32:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_4_window_0/hparams.yaml
2025-04-02 15:33:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:33:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:33:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:33:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:33:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.449628
2025-04-02 15:33:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:33:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:33:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:33:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:33:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:33:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.427925
2025-04-02 15:33:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:33:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:33:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:33:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:33:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:33:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.399917
2025-04-02 15:33:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:33:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:33:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:33:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:33:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=3, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.06264155029261492, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_5_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 88.52761675364096, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefb7550>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefb7990>]}, optimizer_kwargs={'weight_decay': 0.0002038073731001974}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.00028414175629051726, 'pct_start': 0.35, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': False})
2025-04-02 15:33:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:33:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:33:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:33:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:33:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:33:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:33:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:33:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.7 M | train
9  | decoders              | Sequential       | 1.9 M  | train
10 | temporal_decoder      | _ResidualBlock   | 33.6 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
28.6 M    Trainable params
0         Non-trainable params
28.6 M    Total params
114.583   Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:33:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_5_window_0/hparams.yaml
2025-04-02 15:33:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:33:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:33:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:33:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:33:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.490145
2025-04-02 15:33:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:33:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:33:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:33:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:33:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.461732
2025-04-02 15:34:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:34:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.455242
2025-04-02 15:34:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:34:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:34:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:34:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:34:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.19717734201988635, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_6_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 35.43699784556305, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ccc2d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ccf010>]}, optimizer_kwargs={'weight_decay': 0.00018277289537968117}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 3.083497060251547e-05, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 15:34:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:34:04 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:34:04 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:34:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:04 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.7 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.8 M     Trainable params
0         Non-trainable params
5.8 M     Total params
23.037    Total estimated model params size (MB)
49        Modules in train mode
0         Modules in eval mode
2025-04-02 15:34:04 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_6_window_0/hparams.yaml
2025-04-02 15:34:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.373091
2025-04-02 15:34:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:34:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.380953
2025-04-02 15:34:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:34:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.396326
2025-04-02 15:34:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:34:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:34:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:34:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:34:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.3886880987413598, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_7_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5828263374230759, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f4f510>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f4fc10>]}, optimizer_kwargs={'weight_decay': 0.009141398675588318}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1201, 'max_lr': 5.450114280507425e-06, 'pct_start': 0.35, 'div_factor': 45, 'final_div_factor': 100, 'three_phase': False})
2025-04-02 15:34:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:34:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 15:34:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:34:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 12.1 M | train
9  | decoders              | Sequential       | 288 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
12.4 M    Trainable params
0         Non-trainable params
12.4 M    Total params
49.707    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:34:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_7_window_0/hparams.yaml
2025-04-02 15:34:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:34:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.433932
2025-04-02 15:34:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:34:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:34:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:34:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:34:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:35:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.441326
2025-04-02 15:35:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:35:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:35:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:35:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:35:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:35:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.433193
2025-04-02 15:35:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:35:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:35:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:35:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:35:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=3, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.49292493927392594, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_8_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.560995530199157, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feddafd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feddbbd0>]}, optimizer_kwargs={'weight_decay': 0.0038267690999937076}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00010028478094321663, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 100, 'three_phase': False})
2025-04-02 15:35:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:35:05 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:35:05 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:35:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:35:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:35:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:35:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:35:05 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 560 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.2 M    Trainable params
0         Non-trainable params
12.2 M    Total params
48.962    Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:35:05 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_8_window_0/hparams.yaml
2025-04-02 15:36:00 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:36:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.338115
2025-04-02 15:36:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:36:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.346584
2025-04-02 15:36:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:36:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.368757
2025-04-02 15:36:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:36:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:36:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:36:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:36:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.6388351063409251, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_9_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.202471777620392, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefb6890>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefb4d10>]}, optimizer_kwargs={'weight_decay': 0.0002792847569905911}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 1.8739448447112376e-05, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': False})
2025-04-02 15:36:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:36:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:36:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:36:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.780    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:36:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_9_window_0/hparams.yaml
2025-04-02 15:36:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.365152
2025-04-02 15:36:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:36:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.383529
2025-04-02 15:36:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:36:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.408235
2025-04-02 15:36:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:36:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:36:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:36:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:36:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=3, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5054699741663289, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_10_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.4053831470041054, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed4fbd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f47750>]}, optimizer_kwargs={'weight_decay': 0.004188804129914123}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 0.0007344891875240149, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:36:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:36:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 15:36:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:36:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:40 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.9 M | train
9  | decoders              | Sequential       | 560 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
12.5 M    Trainable params
0         Non-trainable params
12.5 M    Total params
50.075    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:36:40 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_10_window_0/hparams.yaml
2025-04-02 15:36:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.404762
2025-04-02 15:36:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:36:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.393687
2025-04-02 15:36:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:36:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.381447
2025-04-02 15:36:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:36:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:36:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:36:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:36:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=3, decoder_output_dim=32, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.49758338919571865, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_11_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 8.776635300883338, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b0e9d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefb4a50>]}, optimizer_kwargs={'weight_decay': 0.0010777993684156567}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 6.319474427274919e-05, 'pct_start': 0.2, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 15:36:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:36:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:36:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:36:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:36:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:36:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:36:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:36:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 141 K  | train
10 | temporal_decoder      | _ResidualBlock   | 14.7 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.673    Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:36:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_11_window_0/hparams.yaml
2025-04-02 15:37:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.35267
2025-04-02 15:37:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:37:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.387334
2025-04-02 15:37:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:37:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.395706
2025-04-02 15:37:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:37:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:37:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:37:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:37:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.2663235210862505, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_12_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 20.208736018860595, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038e7d50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c2d00d0>]}, optimizer_kwargs={'weight_decay': 0.015689691963468526}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 8.53487511923046e-05, 'pct_start': 0.2, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:37:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:37:24 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:37:24 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:37:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:24 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.171    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:37:24 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_12_window_0/hparams.yaml
2025-04-02 15:37:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.366129
2025-04-02 15:37:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:37:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.362645
2025-04-02 15:37:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:37:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.382171
2025-04-02 15:37:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:37:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:37:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:37:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:37:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=3, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.2815964612514243, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_13_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.994707197180321, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103929990>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039446d0>]}, optimizer_kwargs={'weight_decay': 0.026219866929128168}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.00010586599615499475, 'pct_start': 0.3, 'div_factor': 25, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:37:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:37:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:37:50 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:37:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:37:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:37:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:37:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:37:50 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 560 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.171    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:37:50 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_13_window_0/hparams.yaml
2025-04-02 15:38:22 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:38:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.381768
2025-04-02 15:38:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:38:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.379957
2025-04-02 15:38:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:38:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.363551
2025-04-02 15:38:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:38:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:38:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:38:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:38:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.20616964301628077, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_14_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 15.137147919980677, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ad5f10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f243d7390>]}, optimizer_kwargs={'weight_decay': 0.011063669154719324}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0009269858227540261, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:38:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:38:31 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:38:31 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:38:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:31 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.171    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:38:31 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_14_window_0/hparams.yaml
2025-04-02 15:38:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.314735
2025-04-02 15:38:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:38:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.322929
2025-04-02 15:38:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:38:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.354283
2025-04-02 15:38:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:38:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:38:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:38:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:38:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.11773211934679284, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_15_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9138662322894173, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b7e990>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b7fa10>]}, optimizer_kwargs={'weight_decay': 0.002784734940138392}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0008701969896272165, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:38:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:38:53 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:38:53 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:38:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:38:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:38:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:38:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:38:53 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.171    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:38:53 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_15_window_0/hparams.yaml
2025-04-02 15:39:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.325606
2025-04-02 15:39:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:39:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.328148
2025-04-02 15:39:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:39:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.358598
2025-04-02 15:39:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:39:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:39:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:39:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:39:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.11617445079480128, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_16_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 12.284613310887822, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f64d50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f66c50>]}, optimizer_kwargs={'weight_decay': 0.0012649420535290623}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.000853612986511489, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:39:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:39:11 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:39:12 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:39:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:39:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_16_window_0/hparams.yaml
2025-04-02 15:39:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.319178
2025-04-02 15:39:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:39:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.332216
2025-04-02 15:39:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:39:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.370304
2025-04-02 15:39:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:39:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:39:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:39:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:39:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.17091709096487592, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_17_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.791816699077707, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038e5710>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81038e5490>]}, optimizer_kwargs={'weight_decay': 0.04222767472290033}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 0.00031314499181267155, 'pct_start': 0.25, 'div_factor': 25, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:39:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:39:31 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 15:39:31 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:39:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:31 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 12.1 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
12.5 M    Trainable params
0         Non-trainable params
12.5 M    Total params
50.075    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:39:31 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_17_window_0/hparams.yaml
2025-04-02 15:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.416867
2025-04-02 15:39:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.406553
2025-04-02 15:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:39:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.396925
2025-04-02 15:39:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:39:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:39:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:39:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:39:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=32, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.052919749868377663, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_18_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 83.21748786874372, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103df1350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feef0450>]}, optimizer_kwargs={'weight_decay': 0.005750292286896384}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 0.000996146186287655, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:39:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:39:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 15:39:50 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:39:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:39:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:39:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:39:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:39:50 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 12.4 M | train
9  | decoders              | Sequential       | 313 K  | train
10 | temporal_decoder      | _ResidualBlock   | 22.8 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
12.7 M    Trainable params
0         Non-trainable params
12.7 M    Total params
50.959    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:39:50 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_18_window_0/hparams.yaml
2025-04-02 15:40:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.477087
2025-04-02 15:40:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:40:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.427816
2025-04-02 15:40:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:40:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.441132
2025-04-02 15:40:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:40:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:40:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:40:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:40:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.2377240467750743, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_19_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.8780072980093205, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f0c788b50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f24136710>]}, optimizer_kwargs={'weight_decay': 0.002193076693005525}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.00039123365370671604, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:40:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:40:12 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:40:12 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:40:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.2 M    Trainable params
0         Non-trainable params
12.2 M    Total params
48.962    Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:40:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_19_window_0/hparams.yaml
2025-04-02 15:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.340595
2025-04-02 15:40:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:40:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.347687
2025-04-02 15:40:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:40:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.377158
2025-04-02 15:40:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:40:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:40:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:40:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:40:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.14678080130563056, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_20_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.3165514374374996, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103df3310>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103df2b90>]}, optimizer_kwargs={'weight_decay': 0.011405832178759514}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.00047596392334548247, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:40:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:40:30 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:40:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:40:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.171    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:40:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_20_window_0/hparams.yaml
2025-04-02 15:40:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.345811
2025-04-02 15:40:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:40:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.343304
2025-04-02 15:40:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:40:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.368241
2025-04-02 15:40:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:40:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:40:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:40:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:40:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.11780665544783259, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_21_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 15.254478967906715, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bb0950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef88750>]}, optimizer_kwargs={'weight_decay': 0.0015895540034697655}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0009883215088078165, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:40:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:40:48 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:40:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:40:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:40:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:40:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:40:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:40:48 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:40:48 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_21_window_0/hparams.yaml
2025-04-02 15:41:07 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:41:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.378557
2025-04-02 15:41:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:41:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.388713
2025-04-02 15:41:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:41:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.371931
2025-04-02 15:41:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:41:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:41:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:41:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:41:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.1212624805366852, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_22_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 9.275708847180432, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefb4590>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c7a8690>]}, optimizer_kwargs={'weight_decay': 0.0010754161524544822}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.00020518389403114976, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:41:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:41:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:41:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:41:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:41:16 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_22_window_0/hparams.yaml
2025-04-02 15:41:35 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:41:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.37757
2025-04-02 15:41:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:41:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.391712
2025-04-02 15:41:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:41:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.374486
2025-04-02 15:41:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:41:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:41:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:41:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:41:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.31478420749540126, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_23_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 13.37314569229845, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039217d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee31b50>]}, optimizer_kwargs={'weight_decay': 0.0006093581090792682}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.00042991337186886386, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:41:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:41:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:41:44 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:41:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:44 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:41:44 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_23_window_0/hparams.yaml
2025-04-02 15:41:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.332414
2025-04-02 15:41:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:41:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:41:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.337534
2025-04-02 15:41:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:41:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:41:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:41:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:41:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.376225
2025-04-02 15:42:02 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:42:02 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:42:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:42:02 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:42:02 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.2124206132258576, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_24_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 33.5076477077801, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103e39350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e38dd0>]}, optimizer_kwargs={'weight_decay': 0.002846599468689412}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0005907310787005429, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': False})
2025-04-02 15:42:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:42:02 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:42:02 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:42:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:02 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:42:02 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_24_window_0/hparams.yaml
2025-04-02 15:42:21 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:42:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.372515
2025-04-02 15:42:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:42:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.376062
2025-04-02 15:42:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:42:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.367753
2025-04-02 15:42:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:42:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:42:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:42:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:42:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=32, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.08969624934010362, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_25_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.989607200938815, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed00790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c3773d0>]}, optimizer_kwargs={'weight_decay': 0.006496876285993431}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.00017287481640964534, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:42:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:42:30 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:42:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:42:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 313 K  | train
10 | temporal_decoder      | _ResidualBlock   | 33.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.008    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:42:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_25_window_0/hparams.yaml
2025-04-02 15:42:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.340903
2025-04-02 15:42:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:42:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.345871
2025-04-02 15:42:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:42:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.389624
2025-04-02 15:42:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:42:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:42:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:42:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:42:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.16856373035376243, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_26_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 22.979561637106574, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee7ab10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f64126bd0>]}, optimizer_kwargs={'weight_decay': 0.02048005473777123}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 0.0006377227115823569, 'pct_start': 0.25, 'div_factor': 45, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:42:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:42:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:42:50 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:42:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:42:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:42:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:42:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:42:50 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 13.3 M | train
9  | decoders              | Sequential       | 164 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
13.5 M    Trainable params
0         Non-trainable params
13.5 M    Total params
53.860    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:42:50 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_26_window_0/hparams.yaml
2025-04-02 15:43:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.418581
2025-04-02 15:43:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:43:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.394199
2025-04-02 15:43:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:43:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.398346
2025-04-02 15:43:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:43:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:43:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:43:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:43:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=3, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.11213053825581065, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_27_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 9.586454066208068, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feeaa2d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef8ba50>]}, optimizer_kwargs={'weight_decay': 0.0006038770872901756}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 5.834262284314741e-07, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:43:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:43:08 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 15:43:08 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:43:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:09 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 12.6 M | train
9  | decoders              | Sequential       | 560 K  | train
10 | temporal_decoder      | _ResidualBlock   | 33.4 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
13.2 M    Trainable params
0         Non-trainable params
13.2 M    Total params
52.782    Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:43:09 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_27_window_0/hparams.yaml
2025-04-02 15:43:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.437907
2025-04-02 15:43:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:43:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.424762
2025-04-02 15:43:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:43:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.432056
2025-04-02 15:43:19 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:43:19 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:43:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:43:19 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:43:19 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.22626065789335875, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_28_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 62.84379000275811, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d6a4d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef95350>]}, optimizer_kwargs={'weight_decay': 0.001436889049778705}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 4.391371455506322e-05, 'pct_start': 0.3, 'div_factor': 25, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:43:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:43:19 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 15:43:19 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:43:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:19 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.0 M | train
9  | decoders              | Sequential       | 1.2 M  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.3 M    Trainable params
0         Non-trainable params
25.3 M    Total params
101.060   Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:43:19 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_28_window_0/hparams.yaml
2025-04-02 15:43:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.482719
2025-04-02 15:43:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:43:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.438215
2025-04-02 15:43:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:43:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.40987
2025-04-02 15:43:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:43:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:43:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:43:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:43:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=1, decoder_output_dim=32, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.30571171767037436, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_29_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 6.600427978900852, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810471f790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedbbc10>]}, optimizer_kwargs={'weight_decay': 0.08485680339921176}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 1.0404919805105671e-05, 'pct_start': 0.35, 'div_factor': 30, 'final_div_factor': 500, 'three_phase': False})
2025-04-02 15:43:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:43:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 15:43:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:43:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:40 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 6.2 M  | train
9  | decoders              | Sequential       | 41.5 K | train
10 | temporal_decoder      | _ResidualBlock   | 22.8 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
6.3 M     Trainable params
0         Non-trainable params
6.3 M     Total params
25.199    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:43:40 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_29_window_0/hparams.yaml
2025-04-02 15:43:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:43:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.45717
2025-04-02 15:43:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:43:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:43:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:43:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:43:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.449785
2025-04-02 15:44:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:44:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.439601
2025-04-02 15:44:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:44:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:44:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:44:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:44:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=2, decoder_output_dim=64, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.5611982640624836, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_30_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 50.95187597349161, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f65950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f24134490>]}, optimizer_kwargs={'weight_decay': 0.036656108809838876}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0001670513829986689, 'pct_start': 0.25, 'div_factor': 45, 'final_div_factor': 500, 'three_phase': False})
2025-04-02 15:44:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:44:04 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:44:04 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:44:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:04 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 116 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.696    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:44:04 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_30_window_0/hparams.yaml
2025-04-02 15:44:25 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:44:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.324597
2025-04-02 15:44:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:44:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.357902
2025-04-02 15:44:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:44:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.370506
2025-04-02 15:44:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:44:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:44:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:44:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:44:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.32318047936722444, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_31_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 13.375622082149878, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7ee5f0ad50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f09d10>]}, optimizer_kwargs={'weight_decay': 0.0005809075348649291}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0004264309455499083, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:44:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:44:34 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:44:34 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:44:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:34 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:44:34 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_31_window_0/hparams.yaml
2025-04-02 15:44:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.33208
2025-04-02 15:44:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:44:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.338156
2025-04-02 15:44:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:44:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.375874
2025-04-02 15:44:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:44:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:44:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:44:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:44:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.6993592968024156, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_32_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 13.464237401800585, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee8dc10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f4ed90>]}, optimizer_kwargs={'weight_decay': 0.0008295747329138496}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0009374092069462438, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:44:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:44:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:44:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:44:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:44:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:44:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:44:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:44:52 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:44:52 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_32_window_0/hparams.yaml
2025-04-02 15:45:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.310187
2025-04-02 15:45:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:45:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.322906
2025-04-02 15:45:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:45:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.360173
2025-04-02 15:45:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:45:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:45:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:45:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:45:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.15445326975205587, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_33_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 21.158161232011793, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fede97d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ccad90>]}, optimizer_kwargs={'weight_decay': 0.0020128525358540225}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0009663222336409433, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:45:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:45:12 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:45:12 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:45:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.9 M    Trainable params
0         Non-trainable params
11.9 M    Total params
47.462    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:45:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_33_window_0/hparams.yaml
2025-04-02 15:45:31 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 15:45:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.380845
2025-04-02 15:45:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:45:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.381662
2025-04-02 15:45:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:45:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.373159
2025-04-02 15:45:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:45:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:45:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:45:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:45:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=2, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.6052229185611477, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_34_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.33383911158841945, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ae76d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b77690>]}, optimizer_kwargs={'weight_decay': 0.0008334256073382264}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 2.063355692520007e-06, 'pct_start': 0.25, 'div_factor': 40, 'final_div_factor': 250, 'three_phase': False})
2025-04-02 15:45:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:45:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:45:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:45:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:40 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 12.9 M | train
9  | decoders              | Sequential       | 362 K  | train
10 | temporal_decoder      | _ResidualBlock   | 45.2 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
13.3 M    Trainable params
0         Non-trainable params
13.3 M    Total params
53.139    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 15:45:40 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_34_window_0/hparams.yaml
2025-04-02 15:45:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.533122
2025-04-02 15:45:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:45:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.502694
2025-04-02 15:45:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:45:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.481813
2025-04-02 15:45:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:45:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:45:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:45:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:45:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=1, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.42708048194027404, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_35_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 15.734262182577258, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedcd550>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedcd6d0>]}, optimizer_kwargs={'weight_decay': 0.0003186026494604518}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0002579950919855096, 'pct_start': 0.25, 'div_factor': 30, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 15:45:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:45:51 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:45:51 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:45:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:45:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:45:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:45:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:45:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.5 M | train
9  | decoders              | Sequential       | 164 K  | train
10 | temporal_decoder      | _ResidualBlock   | 24.6 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.6 M    Trainable params
0         Non-trainable params
11.6 M    Total params
46.587    Total estimated model params size (MB)
49        Modules in train mode
0         Modules in eval mode
2025-04-02 15:45:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_35_window_0/hparams.yaml
2025-04-02 15:46:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.339576
2025-04-02 15:46:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:46:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.354041
2025-04-02 15:46:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:46:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.3762
2025-04-02 15:46:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:46:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:46:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:46:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:46:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=2, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6992799008647316, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_36_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 6.5023721624291975, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee33510>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee33d90>]}, optimizer_kwargs={'weight_decay': 6.15705741632717e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0005592672355778288, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:46:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:46:29 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:46:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:46:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 1.1 M  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.7 M    Trainable params
0         Non-trainable params
25.7 M    Total params
102.946   Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:46:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_36_window_0/hparams.yaml
2025-04-02 15:46:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.311371
2025-04-02 15:46:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:46:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.328274
2025-04-02 15:46:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:46:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.35868
2025-04-02 15:46:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:46:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:46:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:46:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:46:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=2, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6888415435392212, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_37_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.7786581753985056, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f0c2f23d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c2f04d0>]}, optimizer_kwargs={'weight_decay': 5.54449193584047e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 601, 'max_lr': 0.0006018839002561399, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:46:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:46:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:46:54 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:46:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:46:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:46:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:46:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:46:54 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 1.1 M  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
28.6 M    Trainable params
0         Non-trainable params
28.6 M    Total params
114.301   Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 15:46:54 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_37_window_0/hparams.yaml
2025-04-02 15:47:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:47:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:47:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:47:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:47:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.427454
2025-04-02 15:47:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:47:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:47:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:47:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:47:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:47:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.445081
2025-04-02 15:47:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:47:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:47:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:47:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:47:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:47:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.455303
2025-04-02 15:47:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:47:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:47:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:47:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:47:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6804042157532778, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_38_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9547414490060058, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104642b10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103cb5490>]}, optimizer_kwargs={'weight_decay': 0.00010091442765627965}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00031020248803148896, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:47:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:47:17 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:47:17 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:47:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:47:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:47:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:47:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:47:17 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:47:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_38_window_0/hparams.yaml
2025-04-02 15:48:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.310377
2025-04-02 15:48:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:48:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.327246
2025-04-02 15:48:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:48:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.349988
2025-04-02 15:48:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:48:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:48:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:48:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:48:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.676444669200196, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_39_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7553335942835815, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefaabd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefa9dd0>]}, optimizer_kwargs={'weight_decay': 0.0001366378634248524}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.00028279491405179156, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:48:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:48:10 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 15:48:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:48:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
26.8 M    Trainable params
0         Non-trainable params
26.8 M    Total params
107.360   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:48:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_39_window_0/hparams.yaml
2025-04-02 15:48:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.440193
2025-04-02 15:48:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:48:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.421383
2025-04-02 15:48:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:48:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.422142
2025-04-02 15:48:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:48:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:48:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:48:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:48:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5897593536333299, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_40_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 7.046219580722193, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7ee5f3a110>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f39510>]}, optimizer_kwargs={'weight_decay': 9.328395636560286e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000133608440494313, 'pct_start': 0.3, 'div_factor': 30, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:48:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:48:51 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:48:51 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:48:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:48:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:48:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:48:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:48:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:48:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_40_window_0/hparams.yaml
2025-04-02 15:49:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:49:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:49:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:49:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:49:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.321152
2025-04-02 15:49:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:49:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:49:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:49:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:49:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:49:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.342023
2025-04-02 15:49:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:49:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:49:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:49:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:49:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:49:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.359481
2025-04-02 15:49:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:49:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:49:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:49:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:49:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6493390400809178, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_41_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9073426566007016, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedccb10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f24106750>]}, optimizer_kwargs={'weight_decay': 6.255376846526582e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005495723092827205, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:49:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:49:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:49:45 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:49:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:49:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:49:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:49:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:49:45 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:49:45 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_41_window_0/hparams.yaml
2025-04-02 15:50:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:50:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:50:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:50:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:50:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299162
2025-04-02 15:50:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:50:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:50:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:50:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:50:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:50:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315596
2025-04-02 15:50:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:50:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:50:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:50:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:50:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:50:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339371
2025-04-02 15:50:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:50:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:50:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:50:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:50:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6576823512040946, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_42_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.4632849729595501, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee31850>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f2413a4d0>]}, optimizer_kwargs={'weight_decay': 7.793031556892023e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005222994011612027, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:50:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:50:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:50:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:50:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:50:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:50:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:50:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:50:40 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:50:40 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_42_window_0/hparams.yaml
2025-04-02 15:51:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:51:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:51:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:51:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:51:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299747
2025-04-02 15:51:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:51:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:51:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:51:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:51:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:51:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.320343
2025-04-02 15:51:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:51:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:51:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:51:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:51:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:51:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342155
2025-04-02 15:51:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:51:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:51:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:51:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:51:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6542948157468418, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_43_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.48416183897100346, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f44dd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ae68d0>]}, optimizer_kwargs={'weight_decay': 8.507287726584174e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0003251265765599233, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:51:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:51:26 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:51:26 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:51:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:51:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:51:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:51:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:51:26 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:51:26 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_43_window_0/hparams.yaml
2025-04-02 15:52:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:52:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:52:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:52:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:52:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.309075
2025-04-02 15:52:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:52:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:52:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:52:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:52:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:52:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.326628
2025-04-02 15:52:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:52:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:52:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:52:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:52:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:52:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.349455
2025-04-02 15:52:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:52:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:52:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:52:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:52:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5558184913018289, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_44_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7710417780599601, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef6e290>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103da47d0>]}, optimizer_kwargs={'weight_decay': 8.319168997811205e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00025907451241484307, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:52:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:52:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:52:17 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:52:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:52:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:52:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:52:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:52:17 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:52:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_44_window_0/hparams.yaml
2025-04-02 15:53:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.313684
2025-04-02 15:53:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:53:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.330371
2025-04-02 15:53:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:53:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.35269
2025-04-02 15:53:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:53:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:53:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:53:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:53:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6357713568820751, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_45_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.47614503127128044, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103947550>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810471fed0>]}, optimizer_kwargs={'weight_decay': 0.00015038521904134794}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.0003560487446472313, 'pct_start': 0.3, 'div_factor': 45, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:53:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:53:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 15:53:09 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:53:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:09 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:53:09 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_45_window_0/hparams.yaml
2025-04-02 15:53:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.387157
2025-04-02 15:53:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.378506
2025-04-02 15:53:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:53:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.390361
2025-04-02 15:53:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:53:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:53:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:53:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:53:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6636089739621167, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_46_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.45791700039876904, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810399a810>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feddad10>]}, optimizer_kwargs={'weight_decay': 0.00022395149617057268}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 4.9987843246563824e-05, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:53:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:53:56 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:53:56 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:53:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:53:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:53:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:53:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:53:56 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:53:56 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_46_window_0/hparams.yaml
2025-04-02 15:54:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:54:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:54:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:54:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:54:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.32166
2025-04-02 15:54:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:54:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:54:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:54:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:54:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:54:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.352943
2025-04-02 15:54:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:54:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:54:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:54:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:54:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:54:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.366474
2025-04-02 15:54:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:54:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:54:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:54:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:54:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5341182016562712, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_47_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.043090079840469, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d5e910>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d5d190>]}, optimizer_kwargs={'weight_decay': 5.13310258813319e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00011478523746005428, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:54:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:54:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:54:43 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:54:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:54:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:54:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:54:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:54:43 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:54:43 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_47_window_0/hparams.yaml
2025-04-02 15:55:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:55:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:55:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:55:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:55:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.324021
2025-04-02 15:55:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:55:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:55:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:55:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:55:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:55:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.345315
2025-04-02 15:55:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:55:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:55:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:55:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:55:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:55:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.359913
2025-04-02 15:55:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:55:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:55:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:55:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:55:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6104203742394394, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_48_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.38296984278670687, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103df89d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefb4810>]}, optimizer_kwargs={'weight_decay': 0.00011473121600721878}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.00024576326277769877, 'pct_start': 0.3, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 15:55:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:55:34 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 15:55:34 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:55:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:55:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:55:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:55:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:55:34 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.145   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:55:34 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_48_window_0/hparams.yaml
2025-04-02 15:56:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:56:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:56:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:56:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:56:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.445995
2025-04-02 15:56:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:56:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:56:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:56:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:56:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:56:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.435667
2025-04-02 15:56:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:56:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:56:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:56:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:56:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:56:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.438526
2025-04-02 15:56:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:56:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:56:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:56:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:56:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6632213612309721, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_49_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0252694557502915, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103a18a10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ae6950>]}, optimizer_kwargs={'weight_decay': 0.0003787507710273977}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00014697179622676012, 'pct_start': 0.35, 'div_factor': 25, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 15:56:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:56:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:56:17 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:56:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:56:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:56:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:56:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:56:17 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:56:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_49_window_0/hparams.yaml
2025-04-02 15:57:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.319695
2025-04-02 15:57:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:57:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.339895
2025-04-02 15:57:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:57:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.358847
2025-04-02 15:57:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:57:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:57:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:57:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:57:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5799844942952622, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_50_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6174486181883643, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103a897d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103a8b790>]}, optimizer_kwargs={'weight_decay': 7.996922057181524e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 7.379529872872824e-05, 'pct_start': 0.2, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:57:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:57:17 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:57:17 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:57:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:17 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:57:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_50_window_0/hparams.yaml
2025-04-02 15:57:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.321861
2025-04-02 15:57:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:57:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.351495
2025-04-02 15:57:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:57:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.366887
2025-04-02 15:57:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:57:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:57:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:57:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:57:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6432164626175569, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_51_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.30591836683174406, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefa9dd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103bba710>]}, optimizer_kwargs={'weight_decay': 0.00019655512798126356}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007073834792938908, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:57:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:57:56 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:57:57 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:57:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:57:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:57:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:57:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:57:57 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:57:57 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_51_window_0/hparams.yaml
2025-04-02 15:58:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:58:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:58:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:58:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:58:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295361
2025-04-02 15:58:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:58:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:58:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:58:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:58:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:58:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310224
2025-04-02 15:58:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:58:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:58:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:58:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:58:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:58:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339994
2025-04-02 15:58:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:58:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:58:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:58:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:58:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6346640375733601, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_52_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.3320313556665161, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103cb67d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f64c50>]}, optimizer_kwargs={'weight_decay': 0.00018405958118838697}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006880697155282525, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:58:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:58:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:58:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:58:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:58:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:58:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:58:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:58:52 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:58:52 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_52_window_0/hparams.yaml
2025-04-02 15:59:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:59:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:59:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:59:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:59:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295781
2025-04-02 15:59:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 15:59:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:59:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:59:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:59:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:59:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312284
2025-04-02 15:59:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 15:59:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:59:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:59:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:59:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:59:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340109
2025-04-02 15:59:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 15:59:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 15:59:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 15:59:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 15:59:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6394699383621536, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_53_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.3151312921004923, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7ee5f0ff90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104735b10>]}, optimizer_kwargs={'weight_decay': 0.00018697764064036257}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0004954520987159485, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 15:59:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 15:59:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 15:59:44 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 15:59:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 15:59:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 15:59:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 15:59:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 15:59:44 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 15:59:44 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_53_window_0/hparams.yaml
2025-04-02 16:00:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:00:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:00:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:00:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:00:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301792
2025-04-02 16:00:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:00:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:00:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:00:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:00:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:00:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.320907
2025-04-02 16:00:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:00:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:00:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:00:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:00:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:00:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.345727
2025-04-02 16:00:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:00:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:00:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:00:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:00:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6519886760303139, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_54_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.32809852937191997, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ce1350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ce2390>]}, optimizer_kwargs={'weight_decay': 0.00021319950919985154}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005098317885462673, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 16:00:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:00:30 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:00:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:00:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:00:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:00:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:00:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:00:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:00:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_54_window_0/hparams.yaml
2025-04-02 16:01:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:01:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:01:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:01:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:01:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.298781
2025-04-02 16:01:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:01:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:01:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:01:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:01:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:01:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.317838
2025-04-02 16:01:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:01:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:01:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:01:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:01:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:01:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34112
2025-04-02 16:01:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:01:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:01:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:01:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:01:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6284318898989388, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_55_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.3119268364490121, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee68650>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f39f10>]}, optimizer_kwargs={'weight_decay': 0.000205077027253811}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.0006637524591180627, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 16:01:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:01:18 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 16:01:18 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:01:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:01:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:01:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:01:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:01:18 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:01:18 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_55_window_0/hparams.yaml
2025-04-02 16:01:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:01:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:01:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:01:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.381628
2025-04-02 16:02:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:02:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.359977
2025-04-02 16:02:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:02:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.370875
2025-04-02 16:02:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:02:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:02:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:02:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:02:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.44791943913977095, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_56_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.3848754162951013, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810469aa90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104699650>]}, optimizer_kwargs={'weight_decay': 0.00016167292492494915}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0004828539711331274, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 16:02:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:02:06 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:02:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:02:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:07 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:02:07 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_56_window_0/hparams.yaml
2025-04-02 16:02:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301856
2025-04-02 16:02:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:02:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.317644
2025-04-02 16:02:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:02:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.347862
2025-04-02 16:02:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:02:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:02:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:02:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:02:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.4458532576898246, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_57_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.40665667035539266, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038a1350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f2427a690>]}, optimizer_kwargs={'weight_decay': 0.00039446122702207527}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007136669523546338, 'pct_start': 0.3, 'div_factor': 40, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 16:02:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:02:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:02:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:02:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:02:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:02:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:02:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:02:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:02:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_57_window_0/hparams.yaml
2025-04-02 16:03:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:03:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:03:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:03:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:03:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295838
2025-04-02 16:03:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:03:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:03:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:03:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:03:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:03:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311766
2025-04-02 16:03:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:03:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:03:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:03:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:03:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:03:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.344632
2025-04-02 16:03:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:03:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:03:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:03:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:03:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5392197397035443, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_58_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6630996448663505, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef2f310>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d2cbd0>]}, optimizer_kwargs={'weight_decay': 0.00029552824400233036}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007106297216006748, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:03:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:03:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:03:43 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:03:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:03:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:03:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:03:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:03:43 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:03:43 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_58_window_0/hparams.yaml
2025-04-02 16:04:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:04:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:04:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:04:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:04:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294241
2025-04-02 16:04:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:04:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:04:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:04:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:04:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:04:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314153
2025-04-02 16:04:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:04:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:04:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:04:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:04:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:04:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.348182
2025-04-02 16:04:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:04:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:04:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:04:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:04:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5141628319198259, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_59_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6050048178986219, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039d6210>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed4f790>]}, optimizer_kwargs={'weight_decay': 0.00042807009001470496}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0001995122871389023, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:04:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:04:29 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:04:29 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:04:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:04:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:04:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:04:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:04:29 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:04:29 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_59_window_0/hparams.yaml
2025-04-02 16:04:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:04:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:04:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:04:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:04:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.328647
2025-04-02 16:04:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:04:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:04:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:04:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:04:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.346229
2025-04-02 16:05:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:05:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:05:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:05:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:05:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.359084
2025-04-02 16:05:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:05:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:05:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:05:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:05:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.47340456053792984, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_60_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.5999716503201036, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ccf5d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d2fad0>]}, optimizer_kwargs={'weight_decay': 0.00025882745746615783}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0007710431658501257, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:05:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:05:05 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 16:05:05 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:05:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:05:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:05:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:05:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:05 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
26.8 M    Trainable params
0         Non-trainable params
26.8 M    Total params
107.360   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:05:05 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_60_window_0/hparams.yaml
2025-04-02 16:05:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:05:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:05:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:05:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.436166
2025-04-02 16:05:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:05:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:05:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:05:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:05:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.41698
2025-04-02 16:05:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:05:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:05:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:05:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:05:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.420156
2025-04-02 16:05:38 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:05:38 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:05:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:05:38 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:05:38 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.605780244830563, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_61_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7026925372268107, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104509350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef2d410>]}, optimizer_kwargs={'weight_decay': 0.00045478204265412024}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006853877822864662, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:05:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:05:38 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:05:39 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:05:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:05:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:05:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:05:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:05:39 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:05:39 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_61_window_0/hparams.yaml
2025-04-02 16:06:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:06:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:06:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:06:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:06:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292831
2025-04-02 16:06:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:06:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:06:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:06:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:06:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:06:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312638
2025-04-02 16:06:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:06:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:06:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:06:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:06:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:06:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339269
2025-04-02 16:06:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:06:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:06:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:06:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:06:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.3913634295216481, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_62_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7423749244797015, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81046734d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103bcd6d0>]}, optimizer_kwargs={'weight_decay': 0.000426537002067084}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007510697249485548, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:06:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:06:23 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:06:23 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:06:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:06:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:06:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:06:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:06:23 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:06:23 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_62_window_0/hparams.yaml
2025-04-02 16:07:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.297499
2025-04-02 16:07:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:07:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31229
2025-04-02 16:07:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:07:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.346018
2025-04-02 16:07:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:07:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:07:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:07:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:07:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.3688521915894858, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_63_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7732420152430207, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047e4d50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104788890>]}, optimizer_kwargs={'weight_decay': 0.00043577616319417396}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007398620534182555, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:07:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:07:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:07:09 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:07:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:09 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:07:09 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_63_window_0/hparams.yaml
2025-04-02 16:07:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296548
2025-04-02 16:07:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:07:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31351
2025-04-02 16:07:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:07:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.347357
2025-04-02 16:07:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:07:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:07:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:07:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:07:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.41361415537179763, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_64_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.3172661294510295, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed4e8d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103dac490>]}, optimizer_kwargs={'weight_decay': 0.0003121445876546083}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007271887389137288, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:07:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:07:49 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:07:49 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:07:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:07:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:07:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:07:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:07:49 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:07:49 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_64_window_0/hparams.yaml
2025-04-02 16:08:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:08:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:08:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:08:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:08:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295752
2025-04-02 16:08:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:08:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:08:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:08:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:08:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:08:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312571
2025-04-02 16:08:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:08:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:08:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:08:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:08:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:08:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.345003
2025-04-02 16:08:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:08:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:08:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:08:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:08:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.39711709306750004, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_65_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.376220624547214, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ad5050>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810397e550>]}, optimizer_kwargs={'weight_decay': 0.0007822784262157652}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 1.910496924826233e-05, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:08:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:08:32 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:08:32 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:08:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:08:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:08:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:08:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:08:32 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.435    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:08:32 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_65_window_0/hparams.yaml
2025-04-02 16:09:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:09:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:09:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:09:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:09:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.346272
2025-04-02 16:09:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:09:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:09:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:09:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:09:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:09:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.360715
2025-04-02 16:09:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:09:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:09:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:09:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:09:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:09:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.38328
2025-04-02 16:09:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:09:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:09:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:09:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:09:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.4071566663818916, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_66_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.3356275594634437, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f24279390>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f2427a550>]}, optimizer_kwargs={'weight_decay': 0.00036807290515703374}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0003818509596377404, 'pct_start': 0.35, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:09:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:09:24 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:09:24 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:09:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:09:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:09:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:09:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:09:24 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:09:24 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_66_window_0/hparams.yaml
2025-04-02 16:10:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.335834
2025-04-02 16:10:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:10:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.331239
2025-04-02 16:10:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:10:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.35517
2025-04-02 16:10:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:10:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:10:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:10:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:10:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.3382959036138368, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_67_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8530137003134042, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c60250>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d82910>]}, optimizer_kwargs={'weight_decay': 0.0004787855949455183}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.000748889625696912, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:10:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:10:25 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:10:25 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:10:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:25 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:10:25 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_67_window_0/hparams.yaml
2025-04-02 16:10:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.298348
2025-04-02 16:10:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:10:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.318279
2025-04-02 16:10:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:10:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.348418
2025-04-02 16:10:55 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:10:55 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:10:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:10:55 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:10:55 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.42978609627536923, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_68_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.4072902100943706, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103cc97d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d2d510>]}, optimizer_kwargs={'weight_decay': 0.00012972168431479603}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.0004161447547197173, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 16:10:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:10:55 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 16:10:55 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:10:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:10:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:10:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:10:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:10:56 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:10:56 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_68_window_0/hparams.yaml
2025-04-02 16:11:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.390617
2025-04-02 16:11:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:11:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.380592
2025-04-02 16:11:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:11:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.390002
2025-04-02 16:11:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:11:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:11:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:11:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:11:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.37149992999226655, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_69_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5584914448070959, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81046af8d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ca41d0>]}, optimizer_kwargs={'weight_decay': 0.0002927716657012366}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 4.286000927979469e-06, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:11:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:11:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:11:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:11:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.414    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:11:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_69_window_0/hparams.yaml
2025-04-02 16:11:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.365732
2025-04-02 16:11:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:11:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.385081
2025-04-02 16:11:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:11:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.374893
2025-04-02 16:11:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:11:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:11:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:11:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:11:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.44716857719767167, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_70_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.2696552961806735, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed70450>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b58490>]}, optimizer_kwargs={'weight_decay': 0.0010541678330769043}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0006576795237037001, 'pct_start': 0.3, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:11:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:11:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 16:11:55 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:11:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:11:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:11:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:11:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:11:55 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.165   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:11:55 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_70_window_0/hparams.yaml
2025-04-02 16:12:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:12:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:12:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:12:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:12:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.406147
2025-04-02 16:12:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:12:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:12:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:12:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:12:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:12:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.40918
2025-04-02 16:12:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:12:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:12:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:12:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:12:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:12:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.417674
2025-04-02 16:12:21 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:12:21 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:12:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:12:21 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:12:21 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.608160654207097, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_71_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6975183893978787, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f0c755ad0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed4fe50>]}, optimizer_kwargs={'weight_decay': 0.0004923504081769441}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007977220872559522, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:12:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:12:21 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:12:21 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:12:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:12:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:12:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:12:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:12:21 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:12:21 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_71_window_0/hparams.yaml
2025-04-02 16:12:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:12:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:12:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:12:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:12:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292704
2025-04-02 16:12:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:12:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:12:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:12:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:12:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311456
2025-04-02 16:13:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:13:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:13:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:13:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:13:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339656
2025-04-02 16:13:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:13:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:13:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:13:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:13:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.611131321686585, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_72_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6767042569950977, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7ee5f39950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81038a0b50>]}, optimizer_kwargs={'weight_decay': 0.0005082839996092441}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008416267790898972, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:13:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:13:04 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:13:04 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:13:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:13:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:13:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:13:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:04 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:13:04 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_72_window_0/hparams.yaml
2025-04-02 16:13:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:13:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:13:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:13:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292994
2025-04-02 16:13:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:13:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:13:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:13:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:13:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310196
2025-04-02 16:13:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:13:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:13:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:13:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:13:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340101
2025-04-02 16:13:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:13:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:13:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:13:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:13:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6105509370123603, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_73_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.536481961034991, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef6e210>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ca6650>]}, optimizer_kwargs={'weight_decay': 0.0006492823811935003}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 1.1416328427070666e-05, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:13:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:13:49 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:13:49 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:13:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:13:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:13:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:13:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:13:49 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:13:49 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_73_window_0/hparams.yaml
2025-04-02 16:14:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:14:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:14:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:14:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:14:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.33775
2025-04-02 16:14:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:14:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:14:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:14:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:14:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:14:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.372875
2025-04-02 16:14:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:14:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:14:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:14:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:14:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:14:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.379817
2025-04-02 16:14:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:14:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:14:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:14:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:14:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5887944258433808, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_74_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.40481653690696, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104730110>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c81390>]}, optimizer_kwargs={'weight_decay': 0.00032627438712809124}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009810914797229488, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:14:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:14:32 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:14:32 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:14:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:14:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:14:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:14:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:14:32 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:14:32 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_74_window_0/hparams.yaml
2025-04-02 16:15:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.316241
2025-04-02 16:15:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:15:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.330411
2025-04-02 16:15:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:15:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.352595
2025-04-02 16:15:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:15:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:15:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:15:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:15:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5656111511380726, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_75_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6456525935001386, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104647510>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feeb6090>]}, optimizer_kwargs={'weight_decay': 0.0005037830136783764}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005956367435066221, 'pct_start': 0.2, 'div_factor': 25, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:15:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:15:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:15:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:15:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:15:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_75_window_0/hparams.yaml
2025-04-02 16:15:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301431
2025-04-02 16:15:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:15:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.319911
2025-04-02 16:15:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:15:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.344847
2025-04-02 16:15:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:15:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:15:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:15:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:15:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6107472951437224, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_76_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8854345319987812, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed01690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed03a50>]}, optimizer_kwargs={'weight_decay': 0.0002488065797750261}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0003714931727288218, 'pct_start': 0.3, 'div_factor': 45, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 16:15:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:15:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:15:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:15:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:15:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:15:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:15:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:15:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:15:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_76_window_0/hparams.yaml
2025-04-02 16:16:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:16:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:16:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:16:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:16:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.306241
2025-04-02 16:16:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:16:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:16:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:16:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:16:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:16:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.324982
2025-04-02 16:16:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:16:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:16:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:16:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:16:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:16:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.348132
2025-04-02 16:16:45 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:16:45 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:16:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:16:45 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:16:45 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6234189986196148, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_77_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1312689741312072, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bc6710>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c2f0310>]}, optimizer_kwargs={'weight_decay': 0.0007846804341871496}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1201, 'max_lr': 0.0008699602024240595, 'pct_start': 0.3, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:16:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:16:45 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 16:16:46 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:16:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:16:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:16:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:16:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:16:46 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
26.8 M    Trainable params
0         Non-trainable params
26.8 M    Total params
107.360   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:16:46 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_77_window_0/hparams.yaml
2025-04-02 16:17:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:17:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:17:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:17:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:17:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.447668
2025-04-02 16:17:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:17:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:17:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:17:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:17:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:17:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.430568
2025-04-02 16:17:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:17:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:17:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:17:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:17:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:17:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.429432
2025-04-02 16:17:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:17:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:17:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:17:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:17:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5208134369773711, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_78_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5222997944436054, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810471d290>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810471ca90>]}, optimizer_kwargs={'weight_decay': 0.0001657716512137234}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00047446853529778556, 'pct_start': 0.35, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:17:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:17:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:17:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:17:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:17:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:17:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:17:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:17:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:17:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_78_window_0/hparams.yaml
2025-04-02 16:18:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:18:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:18:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:18:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:18:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.3006
2025-04-02 16:18:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:18:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:18:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:18:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:18:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:18:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315668
2025-04-02 16:18:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:18:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:18:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:18:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:18:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:18:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.346886
2025-04-02 16:18:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:18:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:18:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:18:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:18:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.47973339721154357, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_79_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.4592307480356702, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed097d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee32450>]}, optimizer_kwargs={'weight_decay': 0.000688030310204304}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00022412546578127733, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:18:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:18:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:18:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:18:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:18:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:18:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:18:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:18:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.414    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:18:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_79_window_0/hparams.yaml
2025-04-02 16:18:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:18:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:18:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:18:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:18:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.319774
2025-04-02 16:18:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:19:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.333537
2025-04-02 16:19:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:19:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.366396
2025-04-02 16:19:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:19:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:19:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:19:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:19:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=3, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.5932685201541796, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_80_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.3730155937695491, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee797d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedaa910>]}, optimizer_kwargs={'weight_decay': 0.00011157638611169148}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 1.4393966623381937e-06, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 500, 'three_phase': True})
2025-04-02 16:19:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:19:06 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:19:06 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:19:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:06 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 1.9 M  | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
26.5 M    Trainable params
0         Non-trainable params
26.5 M    Total params
106.123   Total estimated model params size (MB)
81        Modules in train mode
0         Modules in eval mode
2025-04-02 16:19:06 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_80_window_0/hparams.yaml
2025-04-02 16:19:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.388032
2025-04-02 16:19:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:19:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.396872
2025-04-02 16:19:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:19:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.422911
2025-04-02 16:19:20 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:19:20 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:19:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:19:20 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:19:20 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.3466491992628175, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_81_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6822009141343522, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104719f10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810471b250>]}, optimizer_kwargs={'weight_decay': 0.000363885181877179}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008260205924184028, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:19:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:19:20 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:19:20 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:19:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:20 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:19:20 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_81_window_0/hparams.yaml
2025-04-02 16:19:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29507
2025-04-02 16:19:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:19:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:19:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311563
2025-04-02 16:19:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:19:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:19:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:19:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:19:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:20:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.346728
2025-04-02 16:20:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:20:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:20:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:20:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:20:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5713335710719845, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_82_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.5204835325513901, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038fd150>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810463ced0>]}, optimizer_kwargs={'weight_decay': 0.00036580864609617045}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005796118167065489, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:20:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:20:01 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:20:01 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:20:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:20:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:20:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:20:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:20:02 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:20:02 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_82_window_0/hparams.yaml
2025-04-02 16:20:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:20:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:20:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:20:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:20:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295431
2025-04-02 16:20:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:20:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:20:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:20:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:20:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:20:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315148
2025-04-02 16:20:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:20:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:20:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:20:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:20:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:20:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34114
2025-04-02 16:20:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:20:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:20:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:20:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:20:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5711484698625353, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_83_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.528937874467657, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f2426cf50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f2e7d0>]}, optimizer_kwargs={'weight_decay': 0.0003284988073145918}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008034868205770985, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:20:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:20:47 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:20:47 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:20:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:20:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:20:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:20:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:20:47 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:20:47 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_83_window_0/hparams.yaml
2025-04-02 16:21:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:21:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:21:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:21:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:21:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292603
2025-04-02 16:21:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:21:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:21:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:21:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:21:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:21:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310734
2025-04-02 16:21:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:21:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:21:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:21:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:21:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:21:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341346
2025-04-02 16:21:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:21:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:21:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:21:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:21:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5703528387871359, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_84_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9184958809338482, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c6d290>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104518410>]}, optimizer_kwargs={'weight_decay': 0.0005015740666422907}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006553675268719277, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:21:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:21:31 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:21:31 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:21:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:21:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:21:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:21:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:21:31 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:21:31 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_84_window_0/hparams.yaml
2025-04-02 16:22:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:22:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:22:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:22:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:22:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293388
2025-04-02 16:22:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:22:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:22:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:22:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:22:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:22:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311848
2025-04-02 16:22:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:22:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:22:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:22:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:22:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:22:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339755
2025-04-02 16:22:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:22:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:22:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:22:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:22:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5614913755631835, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_85_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.2936074396181865, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810397f590>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c754490>]}, optimizer_kwargs={'weight_decay': 0.0005453542740223566}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0003229508096637618, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:22:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:22:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:22:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:22:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:22:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:22:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:22:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:22:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:22:16 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_85_window_0/hparams.yaml
2025-04-02 16:23:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:23:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.321515
2025-04-02 16:23:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:23:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:23:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.324549
2025-04-02 16:23:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:23:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:23:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.346862
2025-04-02 16:23:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:23:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:23:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:23:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:23:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.543907323239544, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_86_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.6373139270106138, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810392fb50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b7ead0>]}, optimizer_kwargs={'weight_decay': 0.001053657289826364}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005870141050431972, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:23:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:23:10 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:23:11 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:23:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:23:11 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:23:11 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_86_window_0/hparams.yaml
2025-04-02 16:23:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:23:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29847
2025-04-02 16:23:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:23:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:23:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314163
2025-04-02 16:23:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:23:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:23:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:23:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:23:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:24:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34397
2025-04-02 16:24:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:24:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:24:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:24:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:24:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5768019068774478, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_87_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.410289109655031, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b4dd50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103bcd4d0>]}, optimizer_kwargs={'weight_decay': 0.00026112832545415447}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.00042722642416539867, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:24:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:24:03 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 16:24:03 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:24:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:24:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:24:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:24:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:24:03 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.145   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:24:03 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_87_window_0/hparams.yaml
2025-04-02 16:24:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:24:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:24:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:24:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:24:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.439875
2025-04-02 16:24:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:24:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:24:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:24:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:24:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:24:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.426119
2025-04-02 16:24:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:24:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:24:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:24:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:24:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:24:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.425646
2025-04-02 16:24:46 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:24:46 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:24:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:24:46 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:24:46 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.6202033022361468, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_88_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.0711704829055075, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810456d190>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed3b590>]}, optimizer_kwargs={'weight_decay': 0.0005281794348041424}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009569150201976526, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:24:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:24:46 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:24:46 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:24:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:24:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:24:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:24:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:24:46 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.780    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:24:46 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_88_window_0/hparams.yaml
2025-04-02 16:25:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:25:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:25:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:25:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:25:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.30852
2025-04-02 16:25:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:25:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:25:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:25:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:25:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:25:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.319882
2025-04-02 16:25:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:25:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:25:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:25:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:25:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:25:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.347535
2025-04-02 16:25:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:25:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:25:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:25:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:25:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.49609714227681745, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_89_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.5751211008626693, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810469dd10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e58fd0>]}, optimizer_kwargs={'weight_decay': 0.001542202379554185}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 3.0448265957556556e-05, 'pct_start': 0.3, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:25:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:25:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 16:25:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:25:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:25:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:25:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:25:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:25:43 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:25:43 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_89_window_0/hparams.yaml
2025-04-02 16:26:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.409488
2025-04-02 16:26:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:26:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.411509
2025-04-02 16:26:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:26:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.418347
2025-04-02 16:26:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:26:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:26:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:26:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:26:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5966570056524246, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_90_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.736830514510208, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104659350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810465b8d0>]}, optimizer_kwargs={'weight_decay': 0.00023335693117816338}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0006184441632203026, 'pct_start': 0.3, 'div_factor': 25, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:26:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:26:26 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:26:26 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:26:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:26 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 23.8 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.2 M    Trainable params
0         Non-trainable params
24.2 M    Total params
96.634    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 16:26:26 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_90_window_0/hparams.yaml
2025-04-02 16:26:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.304017
2025-04-02 16:26:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:26:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314911
2025-04-02 16:26:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:26:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.347526
2025-04-02 16:26:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:26:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:26:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:26:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:26:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5706705368713235, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_91_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.090952667606669, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104504cd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d5f0d0>]}, optimizer_kwargs={'weight_decay': 0.0003450087158064804}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008092084369213053, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:26:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:26:53 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:26:53 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:26:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:26:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:26:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:26:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:26:53 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:26:53 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_91_window_0/hparams.yaml
2025-04-02 16:27:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:27:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:27:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:27:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:27:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295401
2025-04-02 16:27:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:27:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:27:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:27:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:27:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:27:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309746
2025-04-02 16:27:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:27:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:27:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:27:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:27:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:27:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.343752
2025-04-02 16:27:45 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:27:45 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:27:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:27:45 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:27:45 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.549413440544773, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_92_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9778822870564063, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c44610>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed53310>]}, optimizer_kwargs={'weight_decay': 0.0003620962673671903}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008734677948013224, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:27:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:27:45 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:27:45 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:27:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:27:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:27:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:27:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:27:45 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:27:45 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_92_window_0/hparams.yaml
2025-04-02 16:28:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:28:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:28:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:28:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:28:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293771
2025-04-02 16:28:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:28:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:28:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:28:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:28:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:28:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31052
2025-04-02 16:28:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:28:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:28:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:28:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:28:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:28:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342931
2025-04-02 16:28:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:28:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:28:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:28:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:28:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5756632310404772, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_93_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.1192196542092137, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103cb9310>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103cb8890>]}, optimizer_kwargs={'weight_decay': 0.00019426190255683715}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008306779959836088, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:28:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:28:27 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:28:28 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:28:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:28:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:28:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:28:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:28:28 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:28:28 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_93_window_0/hparams.yaml
2025-04-02 16:29:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293043
2025-04-02 16:29:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:29:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311778
2025-04-02 16:29:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:29:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342565
2025-04-02 16:29:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:29:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:29:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:29:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:29:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5528426572894586, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_94_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.0497337298134064, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee38550>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef9f410>]}, optimizer_kwargs={'weight_decay': 0.00017821896796834595}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008539770450040152, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:29:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:29:11 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:29:12 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:29:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:29:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_94_window_0/hparams.yaml
2025-04-02 16:29:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293251
2025-04-02 16:29:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:29:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314402
2025-04-02 16:29:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:29:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34067
2025-04-02 16:29:46 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:29:46 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:29:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:29:46 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:29:46 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.554065108872115, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_95_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.971960410595772, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103999690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f647d0>]}, optimizer_kwargs={'weight_decay': 0.00016690517991900058}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008796350304972967, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:29:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:29:46 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:29:46 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:29:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:29:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:29:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:29:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:29:46 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:29:46 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_95_window_0/hparams.yaml
2025-04-02 16:30:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:30:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292821
2025-04-02 16:30:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:30:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:30:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313608
2025-04-02 16:30:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:30:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:30:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340059
2025-04-02 16:30:20 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:30:20 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:30:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:30:20 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:30:20 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5255005043181801, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_96_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.8456708277324134, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f2426fb90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d65750>]}, optimizer_kwargs={'weight_decay': 0.00013156244778794623}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005106631190479893, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:30:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:30:20 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:30:20 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:30:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:30:20 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:30:20 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_96_window_0/hparams.yaml
2025-04-02 16:30:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:30:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.308075
2025-04-02 16:30:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:30:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:30:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.326276
2025-04-02 16:30:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:30:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:30:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:30:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:30:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:31:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.349745
2025-04-02 16:31:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:31:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:31:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:31:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:31:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6720006212342039, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_97_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.849658401465013, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103aecd90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ba6fd0>]}, optimizer_kwargs={'weight_decay': 0.00020313538004199227}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0004474025643013567, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:31:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:31:01 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 16:31:01 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:31:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:31:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:31:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:31:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:31:01 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
26.8 M    Trainable params
0         Non-trainable params
26.8 M    Total params
107.360   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:31:01 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_97_window_0/hparams.yaml
2025-04-02 16:31:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:31:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:31:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:31:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:31:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.425447
2025-04-02 16:31:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:31:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:31:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:31:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:31:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:31:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.410575
2025-04-02 16:31:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:31:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:31:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:31:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:31:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:31:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.41645
2025-04-02 16:31:33 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:31:33 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:31:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:31:33 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:31:33 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6330120030179589, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_98_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.15923712304714, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed53a90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810451c0d0>]}, optimizer_kwargs={'weight_decay': 0.00015457306712734567}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008765801676996064, 'pct_start': 0.2, 'div_factor': 45, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:31:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:31:33 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:31:33 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:31:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:31:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:31:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:31:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:31:33 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.414    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:31:33 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_98_window_0/hparams.yaml
2025-04-02 16:31:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:31:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:31:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:31:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.303096
2025-04-02 16:32:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:32:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.319561
2025-04-02 16:32:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:32:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.354614
2025-04-02 16:32:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:32:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:32:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:32:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:32:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6006508599492765, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_99_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.5932964655001, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee817d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee83550>]}, optimizer_kwargs={'weight_decay': 0.000934716009976414}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006329350089196457, 'pct_start': 0.35, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 16:32:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:32:07 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:32:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:32:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:07 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:32:07 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_99_window_0/hparams.yaml
2025-04-02 16:32:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294828
2025-04-02 16:32:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31448
2025-04-02 16:32:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:32:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339413
2025-04-02 16:32:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:32:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:32:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:32:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:32:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5853132666472609, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_100_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.864738662423832, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039317d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103933a10>]}, optimizer_kwargs={'weight_decay': 0.0006914771358816455}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0003439399808773028, 'pct_start': 0.2, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:32:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:32:48 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:32:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:32:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:32:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:32:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:32:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:32:48 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:32:48 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_100_window_0/hparams.yaml
2025-04-02 16:33:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:33:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.32697
2025-04-02 16:33:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:33:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:33:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.331481
2025-04-02 16:33:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:33:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:33:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.354873
2025-04-02 16:33:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:33:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:33:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:33:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:33:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5549410472287599, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_101_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.1701441080160966, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104733790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039e86d0>]}, optimizer_kwargs={'weight_decay': 0.0001811568560074034}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008315452110575867, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:33:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:33:22 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:33:22 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:33:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:33:22 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:33:22 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_101_window_0/hparams.yaml
2025-04-02 16:33:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:33:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294634
2025-04-02 16:33:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:33:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:33:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313424
2025-04-02 16:33:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:33:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:33:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:33:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:33:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:34:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340674
2025-04-02 16:34:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:34:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:34:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:34:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:34:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5489307915318904, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_102_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9112751164487602, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b90250>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f0bc10>]}, optimizer_kwargs={'weight_decay': 0.0002598007202192844}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009469333038814629, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:34:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:34:01 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:34:02 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:34:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:34:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:34:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:34:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:34:02 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:34:02 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_102_window_0/hparams.yaml
2025-04-02 16:34:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:34:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:34:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:34:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:34:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292382
2025-04-02 16:34:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:34:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:34:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:34:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:34:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:34:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312097
2025-04-02 16:34:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:34:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:34:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:34:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:34:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:34:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339993
2025-04-02 16:34:35 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:34:35 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:34:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:34:35 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:34:35 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5402675695788778, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_103_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.834024634027489, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c3f450>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c3e450>]}, optimizer_kwargs={'weight_decay': 0.00026368659700729707}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006993803048662838, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:34:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:34:35 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:34:36 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:34:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:34:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:34:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:34:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:34:36 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:34:36 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_103_window_0/hparams.yaml
2025-04-02 16:35:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299038
2025-04-02 16:35:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:35:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.318245
2025-04-02 16:35:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:35:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342126
2025-04-02 16:35:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:35:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:35:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:35:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:35:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6436866898915513, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_104_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.2797870161376297, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103cea050>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103cc9fd0>]}, optimizer_kwargs={'weight_decay': 0.00046515452047719}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00093102234498752, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:35:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:35:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:35:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:35:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:35:16 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_104_window_0/hparams.yaml
2025-04-02 16:35:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294321
2025-04-02 16:35:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:35:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314569
2025-04-02 16:35:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:35:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339182
2025-04-02 16:35:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:35:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:35:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:35:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:35:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.5104931245181015, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_105_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.3008140478274774, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee3ad50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee38790>]}, optimizer_kwargs={'weight_decay': 0.0004321476402201405}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005463516859084046, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:35:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:35:49 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:35:49 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:35:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:35:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:35:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:35:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:35:49 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.780    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:35:49 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_105_window_0/hparams.yaml
2025-04-02 16:36:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:36:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:36:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:36:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:36:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.308227
2025-04-02 16:36:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:36:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:36:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:36:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:36:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:36:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.332302
2025-04-02 16:36:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:36:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:36:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:36:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:36:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:36:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.355837
2025-04-02 16:36:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:36:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:36:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:36:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:36:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6162214348639494, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_106_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.384497595816382, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047c8290>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81047cb910>]}, optimizer_kwargs={'weight_decay': 0.000471061652605481}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009952364826451862, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:36:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:36:30 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:36:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:36:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:36:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:36:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:36:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:36:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:36:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_106_window_0/hparams.yaml
2025-04-02 16:36:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:36:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:36:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:36:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292378
2025-04-02 16:37:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:37:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312435
2025-04-02 16:37:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:37:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338354
2025-04-02 16:37:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:37:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:37:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:37:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:37:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6085510557429369, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_107_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.4879930846463818, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d91350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810462b0d0>]}, optimizer_kwargs={'weight_decay': 0.0005952611956033897}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008190395888409699, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:37:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:37:06 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:37:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:37:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:07 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:37:07 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_107_window_0/hparams.yaml
2025-04-02 16:37:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295365
2025-04-02 16:37:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:37:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31565
2025-04-02 16:37:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:37:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34097
2025-04-02 16:37:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:37:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:37:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:37:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:37:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6199371695737316, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_108_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0479327321018028, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bcd490>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046ae850>]}, optimizer_kwargs={'weight_decay': 0.0002871442275923879}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006574817957615362, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:37:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:37:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:37:44 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:37:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:37:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:37:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:37:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:37:44 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:37:44 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_108_window_0/hparams.yaml
2025-04-02 16:38:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301334
2025-04-02 16:38:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:38:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.321025
2025-04-02 16:38:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:38:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.344044
2025-04-02 16:38:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:38:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:38:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:38:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:38:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.5776109793949372, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_109_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.439732930898647, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d5c290>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104555b50>]}, optimizer_kwargs={'weight_decay': 0.00022510220734300323}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0009826500879229838, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:38:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:38:18 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 16:38:18 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:38:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:18 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.165   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:38:18 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_109_window_0/hparams.yaml
2025-04-02 16:38:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.409013
2025-04-02 16:38:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:38:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.404319
2025-04-02 16:38:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:38:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.410846
2025-04-02 16:38:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:38:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:38:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:38:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:38:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5324222061332756, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_110_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.7914407848259721, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d684d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e586d0>]}, optimizer_kwargs={'weight_decay': 0.0003375674582682367}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1201, 'max_lr': 0.00044337428313304074, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:38:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:38:49 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 16:38:49 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:38:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:38:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:38:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:38:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:38:49 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:38:49 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_110_window_0/hparams.yaml
2025-04-02 16:39:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.403396
2025-04-02 16:39:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:39:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.414575
2025-04-02 16:39:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:39:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.406468
2025-04-02 16:39:13 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:39:13 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:39:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:39:13 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:39:13 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6499440085918347, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_111_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9797133500215347, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bcf090>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046ad8d0>]}, optimizer_kwargs={'weight_decay': 0.0004564578054259554}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000998394950635405, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:39:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:39:13 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:39:13 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:39:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:13 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:39:13 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_111_window_0/hparams.yaml
2025-04-02 16:39:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292638
2025-04-02 16:39:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313008
2025-04-02 16:39:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339057
2025-04-02 16:39:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:39:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:39:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:39:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5967748355831258, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_112_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.693533962647653, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038f4750>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefcf690>]}, optimizer_kwargs={'weight_decay': 0.0004972056286062704}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009948985387422454, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:39:47 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:39:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:39:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:39:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:39:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:39:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:39:48 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:39:48 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_112_window_0/hparams.yaml
2025-04-02 16:40:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291925
2025-04-02 16:40:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312298
2025-04-02 16:40:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:40:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339315
2025-04-02 16:40:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:40:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:40:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:40:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:40:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6675886006620771, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_113_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.3645520506923141, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bc4d10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e53050>]}, optimizer_kwargs={'weight_decay': 0.0005459588338767024}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00096368155337672, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:40:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:40:27 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:40:27 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:40:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:27 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:40:27 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_113_window_0/hparams.yaml
2025-04-02 16:40:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294858
2025-04-02 16:40:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:40:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314441
2025-04-02 16:40:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:40:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:40:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:40:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:40:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:40:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338138
2025-04-02 16:41:00 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:41:00 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:41:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:41:00 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:41:00 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6500062164275767, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_114_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.133183175319382, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81045e4e90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81045e69d0>]}, optimizer_kwargs={'weight_decay': 0.0007285882943517077}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000560299788026109, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:41:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:41:00 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:41:00 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:41:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:41:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:41:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:41:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:41:00 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:41:00 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_114_window_0/hparams.yaml
2025-04-02 16:41:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:41:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:41:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:41:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:41:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.305391
2025-04-02 16:41:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:41:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:41:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:41:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:41:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:41:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.324621
2025-04-02 16:41:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:41:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:41:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:41:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:41:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:41:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.347911
2025-04-02 16:41:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:41:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:41:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:41:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:41:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.5984429340825813, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_115_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.7121367411713906, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d79bd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feeaaa10>]}, optimizer_kwargs={'weight_decay': 0.001259434662948846}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009983586367008268, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:41:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:41:34 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:41:35 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:41:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:41:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:41:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:41:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:41:35 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.7 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
99.852    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:41:35 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_115_window_0/hparams.yaml
2025-04-02 16:42:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299488
2025-04-02 16:42:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:42:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313676
2025-04-02 16:42:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:42:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.351496
2025-04-02 16:42:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:42:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:42:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:42:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:42:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6174061571282525, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_116_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8213715616335269, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedb97d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c2f2a50>]}, optimizer_kwargs={'weight_decay': 0.000889097767274932}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000718300120626447, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:42:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:42:10 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:42:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:42:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:42:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_116_window_0/hparams.yaml
2025-04-02 16:42:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300465
2025-04-02 16:42:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:42:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.319726
2025-04-02 16:42:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:42:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342026
2025-04-02 16:42:45 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:42:45 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:42:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:42:45 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:42:45 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5515636096416343, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_117_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.7616930546586556, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d1a1d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103cb7450>]}, optimizer_kwargs={'weight_decay': 0.00046889916420851847}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 5.370314512775688e-07, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:42:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:42:45 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:42:45 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:42:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:45 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:42:45 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_117_window_0/hparams.yaml
2025-04-02 16:42:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.354467
2025-04-02 16:42:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:42:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.392688
2025-04-02 16:42:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:42:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.399606
2025-04-02 16:42:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:42:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:42:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:42:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:42:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6845836963747599, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_118_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.4191640553931117, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feee7b10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c47c90>]}, optimizer_kwargs={'weight_decay': 0.0006073648868161625}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006553037515348939, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:42:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:42:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:42:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:42:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:42:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:42:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:42:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:42:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:42:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_118_window_0/hparams.yaml
2025-04-02 16:43:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:43:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:43:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:43:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:43:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301848
2025-04-02 16:43:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:43:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:43:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:43:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:43:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:43:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.321355
2025-04-02 16:43:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:43:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:43:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:43:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:43:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:43:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.344193
2025-04-02 16:43:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:43:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:43:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:43:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:43:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6278003799516038, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_119_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9639190837627034, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103998690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ce9850>]}, optimizer_kwargs={'weight_decay': 0.0004213277965780413}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0007971363770443009, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:43:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:43:32 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 16:43:32 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:43:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:43:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:43:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:43:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:43:32 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 6.3 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
6.3 M     Trainable params
0         Non-trainable params
6.3 M     Total params
25.307    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:43:32 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_119_window_0/hparams.yaml
2025-04-02 16:43:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:43:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:43:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:43:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:43:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.414458
2025-04-02 16:43:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:43:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:43:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:43:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:43:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.397481
2025-04-02 16:44:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:44:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:44:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:44:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:44:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.413124
2025-04-02 16:44:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:44:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:44:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:44:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:44:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5881751436290367, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_120_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9416821723139872, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103a8a0d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedd8110>]}, optimizer_kwargs={'weight_decay': 0.00032322178986235326}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009979672651540539, 'pct_start': 0.2, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': False})
2025-04-02 16:44:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:44:03 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:44:04 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:44:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:44:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:44:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:44:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:04 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:44:04 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_120_window_0/hparams.yaml
2025-04-02 16:44:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:44:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:44:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:44:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.317809
2025-04-02 16:44:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:44:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:44:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:44:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:44:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.327775
2025-04-02 16:44:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:44:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:44:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:44:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:44:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.350636
2025-04-02 16:44:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:44:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:44:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:44:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:44:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5655515904233304, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_121_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.474211355418569, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047fbe90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefabd10>]}, optimizer_kwargs={'weight_decay': 0.000388125259948782}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007854794553036625, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:44:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:44:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:44:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:44:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:44:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:44:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:44:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:44:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:44:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_121_window_0/hparams.yaml
2025-04-02 16:45:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:45:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:45:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:45:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:45:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292366
2025-04-02 16:45:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:45:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:45:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:45:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:45:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:45:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310566
2025-04-02 16:45:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:45:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:45:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:45:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:45:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:45:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341439
2025-04-02 16:45:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:45:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:45:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:45:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:45:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6056125878729771, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_122_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.3991023824458697, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ad7010>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ad6590>]}, optimizer_kwargs={'weight_decay': 0.000505302320200833}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005290247969255752, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:45:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:45:24 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:45:24 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:45:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:45:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:45:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:45:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:45:24 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:45:24 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_122_window_0/hparams.yaml
2025-04-02 16:45:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:45:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:45:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:45:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.298615
2025-04-02 16:46:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:46:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.322586
2025-04-02 16:46:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:46:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.349889
2025-04-02 16:46:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:46:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:46:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:46:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:46:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5638919910656003, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_123_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.7075246182797819, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103dfe210>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d2f150>]}, optimizer_kwargs={'weight_decay': 0.0004026911757338854}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007463167683438234, 'pct_start': 0.35, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:46:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:46:07 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:46:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:46:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:07 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:46:07 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_123_window_0/hparams.yaml
2025-04-02 16:46:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294012
2025-04-02 16:46:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:46:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310554
2025-04-02 16:46:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:46:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.344468
2025-04-02 16:46:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:46:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:46:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:46:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:46:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6385486461198285, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_124_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.2092328033438542, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103929590>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ce84d0>]}, optimizer_kwargs={'weight_decay': 0.00029381340182894086}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006317221481815017, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:46:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:46:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:46:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:46:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:46:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:46:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:46:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:46:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:46:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_124_window_0/hparams.yaml
2025-04-02 16:47:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:47:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:47:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:47:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:47:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296349
2025-04-02 16:47:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:47:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:47:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:47:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:47:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:47:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314928
2025-04-02 16:47:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:47:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:47:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:47:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:47:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:47:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340047
2025-04-02 16:47:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:47:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:47:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:47:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:47:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5983570320757672, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_125_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.9161241122240165, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed312d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f0f390>]}, optimizer_kwargs={'weight_decay': 0.0002426063583748693}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0004927598345272406, 'pct_start': 0.3, 'div_factor': 25, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:47:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:47:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:47:44 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:47:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:47:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:47:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:47:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:47:44 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:47:44 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_125_window_0/hparams.yaml
2025-04-02 16:48:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:48:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:48:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:48:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:48:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29883
2025-04-02 16:48:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:48:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:48:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:48:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:48:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:48:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.318076
2025-04-02 16:48:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:48:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:48:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:48:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:48:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:48:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342438
2025-04-02 16:48:28 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:48:28 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:48:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:48:28 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:48:28 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.549023680942913, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_126_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.6764003645890937, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104640810>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed38a50>]}, optimizer_kwargs={'weight_decay': 0.004218127918166688}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000393343957905701, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:48:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:48:28 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:48:28 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:48:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:48:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:48:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:48:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:48:29 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:48:29 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_126_window_0/hparams.yaml
2025-04-02 16:48:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:48:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:48:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:48:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:48:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.312762
2025-04-02 16:48:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:48:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:48:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:48:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:48:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.331447
2025-04-02 16:49:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:49:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:49:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:49:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:49:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.351504
2025-04-02 16:49:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:49:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:49:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:49:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:49:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5255115981697567, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_127_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.4816083535526237, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed02710>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046ca910>]}, optimizer_kwargs={'weight_decay': 0.000618928421850098}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008512032863405832, 'pct_start': 0.3, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:49:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:49:03 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:49:04 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:49:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:49:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:49:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:49:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:04 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:49:04 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_127_window_0/hparams.yaml
2025-04-02 16:49:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:49:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:49:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:49:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296926
2025-04-02 16:49:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:49:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:49:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:49:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:49:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309965
2025-04-02 16:49:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:49:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:49:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:49:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:49:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.346485
2025-04-02 16:49:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:49:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:49:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:49:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:49:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.5836410255343383, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_128_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.2829467077058754, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103e754d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b18890>]}, optimizer_kwargs={'weight_decay': 0.00037906465712048295}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007369025424471235, 'pct_start': 0.3, 'div_factor': 45, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:49:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:49:59 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:49:59 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:49:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:49:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:49:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:49:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:49:59 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.780    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:49:59 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_128_window_0/hparams.yaml
2025-04-02 16:50:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:50:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:50:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:50:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:50:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.306156
2025-04-02 16:50:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:50:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:50:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:50:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:50:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:50:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.320223
2025-04-02 16:50:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:50:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:50:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:50:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:50:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:50:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.343975
2025-04-02 16:50:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:50:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:50:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:50:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:50:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6616858964825889, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_129_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.186830686669329, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810394e9d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee88f10>]}, optimizer_kwargs={'weight_decay': 0.0005363118270179402}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005879088106864652, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:50:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:50:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:50:55 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:50:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:50:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:50:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:50:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:50:55 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:50:55 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_129_window_0/hparams.yaml
2025-04-02 16:51:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:51:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:51:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:51:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:51:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.297463
2025-04-02 16:51:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:51:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:51:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:51:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:51:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:51:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.316389
2025-04-02 16:51:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:51:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:51:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:51:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:51:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:51:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339494
2025-04-02 16:51:39 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:51:39 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:51:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:51:39 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:51:39 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.6212853073133341, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_130_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.961111658274483, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d9b850>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f0af90>]}, optimizer_kwargs={'weight_decay': 0.00027675526006358064}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000855430491992689, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:51:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:51:39 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:51:39 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:51:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:51:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:51:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:51:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:51:39 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
99.811    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:51:39 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_130_window_0/hparams.yaml
2025-04-02 16:52:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:52:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:52:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:52:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:52:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299248
2025-04-02 16:52:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:52:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:52:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:52:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:52:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:52:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.322081
2025-04-02 16:52:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:52:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:52:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:52:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:52:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:52:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.347554
2025-04-02 16:52:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:52:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:52:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:52:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:52:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.572944301192153, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_131_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.0966281363046364, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047312d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b7de90>]}, optimizer_kwargs={'weight_decay': 0.00020888228556930895}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007997105478743043, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:52:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:52:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:52:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:52:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:52:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:52:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:52:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:52:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:52:16 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_131_window_0/hparams.yaml
2025-04-02 16:53:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295704
2025-04-02 16:53:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:53:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309693
2025-04-02 16:53:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:53:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.343367
2025-04-02 16:53:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:53:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:53:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:53:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:53:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5817838718785796, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_132_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.9517930304461393, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039a0bd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c2f1690>]}, optimizer_kwargs={'weight_decay': 0.00015002986249278909}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007294311628959986, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:53:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:53:14 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:53:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:53:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:53:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_132_window_0/hparams.yaml
2025-04-02 16:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294282
2025-04-02 16:53:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:53:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31157
2025-04-02 16:53:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:53:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339246
2025-04-02 16:53:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:53:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:53:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:53:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:53:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5619301890072587, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_133_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.863825161858938, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee0da10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f2f2d0>]}, optimizer_kwargs={'weight_decay': 0.0001475585687920424}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006665507892942566, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:53:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:53:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:53:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:53:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:53:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:53:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:53:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:53:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:53:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_133_window_0/hparams.yaml
2025-04-02 16:54:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:54:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:54:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:54:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:54:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292708
2025-04-02 16:54:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:54:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:54:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:54:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:54:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:54:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312599
2025-04-02 16:54:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:54:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:54:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:54:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:54:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:54:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.344017
2025-04-02 16:54:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:54:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:54:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:54:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:54:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=3, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.4877757266078332, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_134_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.425108998487626, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104575d10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c1dc10>]}, optimizer_kwargs={'weight_decay': 0.000121235093976762}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000988223798396954, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:54:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:54:51 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:54:51 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:54:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:54:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:54:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:54:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:54:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 1.9 M  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
26.5 M    Trainable params
0         Non-trainable params
26.5 M    Total params
106.102   Total estimated model params size (MB)
81        Modules in train mode
0         Modules in eval mode
2025-04-02 16:54:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_134_window_0/hparams.yaml
2025-04-02 16:55:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:55:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:55:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:55:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:55:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.305519
2025-04-02 16:55:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:55:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:55:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:55:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:55:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:55:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.318862
2025-04-02 16:55:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:55:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:55:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:55:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:55:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:55:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340757
2025-04-02 16:55:41 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:55:41 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:55:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:55:41 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:55:41 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5047168517582991, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_135_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.6325840095240933, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047308d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee32150>]}, optimizer_kwargs={'weight_decay': 0.0003527979868989798}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005224333857842456, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:55:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:55:41 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:55:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:55:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:55:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:55:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:55:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:55:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:55:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_135_window_0/hparams.yaml
2025-04-02 16:56:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:56:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:56:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:56:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:56:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300737
2025-04-02 16:56:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:56:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:56:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:56:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:56:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:56:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314639
2025-04-02 16:56:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:56:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:56:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:56:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:56:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:56:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.345294
2025-04-02 16:56:38 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:56:38 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:56:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:56:38 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:56:38 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5910665344054916, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_136_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 5.867135639820646, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104616b50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d65010>]}, optimizer_kwargs={'weight_decay': 9.479194027151005e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0007145455621697474, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:56:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:56:38 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:56:38 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:56:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:56:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:56:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:56:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:56:38 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:56:38 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_136_window_0/hparams.yaml
2025-04-02 16:57:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:57:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:57:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:57:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:57:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300084
2025-04-02 16:57:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:57:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:57:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:57:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:57:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:57:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.320353
2025-04-02 16:57:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:57:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:57:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:57:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:57:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:57:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342917
2025-04-02 16:57:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:57:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:57:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:57:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:57:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6099445362212498, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_137_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.795757112225723, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103da6110>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e45850>]}, optimizer_kwargs={'weight_decay': 0.0004726699935672811}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006052922855176125, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:57:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:57:11 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:57:11 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:57:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:57:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:57:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:57:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:57:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:57:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_137_window_0/hparams.yaml
2025-04-02 16:57:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:57:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:57:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:57:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.297093
2025-04-02 16:58:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:58:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312683
2025-04-02 16:58:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:58:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34318
2025-04-02 16:58:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:58:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:58:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:58:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:58:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.6396609132903553, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_138_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.975912064250833, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039ff350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039ffa10>]}, optimizer_kwargs={'weight_decay': 0.0007446545974628514}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0008394270683302853, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:58:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:58:08 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 16:58:08 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:58:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:08 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.7 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.206   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:58:08 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_138_window_0/hparams.yaml
2025-04-02 16:58:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.376083
2025-04-02 16:58:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:58:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.386579
2025-04-02 16:58:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:58:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.396147
2025-04-02 16:58:35 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:58:35 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:58:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:58:35 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:58:35 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5397130144846075, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_139_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.5559113221293597, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee31690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feed6f10>]}, optimizer_kwargs={'weight_decay': 0.00024274819139907003}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00048332608601018304, 'pct_start': 0.2, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 16:58:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:58:35 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 16:58:35 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:58:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:58:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:58:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:58:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:58:35 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:58:35 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_139_window_0/hparams.yaml
2025-04-02 16:59:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:59:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:59:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:59:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:59:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.307988
2025-04-02 16:59:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 16:59:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:59:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:59:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:59:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:59:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.324882
2025-04-02 16:59:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 16:59:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:59:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:59:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:59:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:59:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.348653
2025-04-02 16:59:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 16:59:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 16:59:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 16:59:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 16:59:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5839662081123301, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_140_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7457272685823259, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81046717d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104670b10>]}, optimizer_kwargs={'weight_decay': 0.00030533486173842106}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.0006955702607976807, 'pct_start': 0.35, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': False})
2025-04-02 16:59:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 16:59:18 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 16:59:19 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 16:59:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 16:59:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 16:59:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 16:59:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 16:59:19 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 6.0 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
6.1 M     Trainable params
0         Non-trainable params
6.1 M     Total params
24.361    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 16:59:19 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_140_window_0/hparams.yaml
2025-04-02 17:00:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.422443
2025-04-02 17:00:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:00:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.394195
2025-04-02 17:00:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:00:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.391192
2025-04-02 17:00:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:00:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:00:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:00:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:00:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.570953930771604, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_141_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.1204324887854056, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c2c710>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d04390>]}, optimizer_kwargs={'weight_decay': 0.00016633152138217366}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008505101768761727, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:00:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:00:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:00:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:00:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:00:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_141_window_0/hparams.yaml
2025-04-02 17:00:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292591
2025-04-02 17:00:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:00:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310388
2025-04-02 17:00:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:00:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34187
2025-04-02 17:00:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:00:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:00:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:00:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:00:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5675728020936163, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_142_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.8064207459392072, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104731690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104733650>]}, optimizer_kwargs={'weight_decay': 0.0001430181546196357}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009972313581634844, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:00:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:00:59 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:00:59 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:00:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:00:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:00:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:00:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:00:59 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:00:59 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_142_window_0/hparams.yaml
2025-04-02 17:01:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:01:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:01:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:01:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:01:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292988
2025-04-02 17:01:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:01:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:01:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:01:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:01:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:01:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310602
2025-04-02 17:01:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:01:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:01:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:01:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:01:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:01:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.343876
2025-04-02 17:01:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:01:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:01:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:01:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:01:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6038493658699293, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_143_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.0727225817414077, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f2425db50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103bb1690>]}, optimizer_kwargs={'weight_decay': 0.000392833136963504}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006049907760688439, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:01:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:01:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:01:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:01:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:01:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:01:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:01:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:01:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:01:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_143_window_0/hparams.yaml
2025-04-02 17:02:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:02:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:02:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:02:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:02:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295975
2025-04-02 17:02:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:02:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:02:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:02:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:02:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:02:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312132
2025-04-02 17:02:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:02:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:02:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:02:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:02:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:02:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341619
2025-04-02 17:02:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:02:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:02:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:02:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:02:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.27397935982487076, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_144_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.4637505145145435, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047bbed0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103dfa510>]}, optimizer_kwargs={'weight_decay': 0.00016465073076821386}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007891015575785939, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:02:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:02:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:02:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:02:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:02:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:02:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:02:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:02:40 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:02:40 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_144_window_0/hparams.yaml
2025-04-02 17:03:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:03:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:03:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:03:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:03:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295499
2025-04-02 17:03:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:03:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:03:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:03:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:03:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:03:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312789
2025-04-02 17:03:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:03:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:03:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:03:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:03:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:03:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.350783
2025-04-02 17:03:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:03:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:03:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:03:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:03:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6285343080250121, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_145_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.2470304358430684, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810458e210>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee781d0>]}, optimizer_kwargs={'weight_decay': 0.0001156755302804161}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008690689927184021, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:03:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:03:22 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:03:22 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:03:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:03:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:03:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:03:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:03:22 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:03:22 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_145_window_0/hparams.yaml
2025-04-02 17:03:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:03:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:03:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:03:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:03:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291922
2025-04-02 17:03:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:03:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:03:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:03:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:03:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310524
2025-04-02 17:04:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:04:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:04:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:04:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:04:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339939
2025-04-02 17:04:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:04:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:04:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:04:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:04:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6272508857061309, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_146_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.1250509417284595, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f4bd10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f4b350>]}, optimizer_kwargs={'weight_decay': 7.017285421802553e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007671912250774374, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:04:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:04:06 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:04:06 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:04:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:04:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:04:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:04:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:06 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:04:06 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_146_window_0/hparams.yaml
2025-04-02 17:04:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:04:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:04:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:04:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293904
2025-04-02 17:04:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:04:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:04:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:04:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:04:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312631
2025-04-02 17:04:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:04:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:04:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:04:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:04:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339256
2025-04-02 17:04:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:04:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:04:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:04:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:04:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6505360902109901, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_147_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.0691251812834235, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedd2690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103af6d90>]}, optimizer_kwargs={'weight_decay': 6.699921969223225e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0004223314906015644, 'pct_start': 0.3, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:04:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:04:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:04:50 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:04:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:04:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:04:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:04:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:04:50 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:04:50 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_147_window_0/hparams.yaml
2025-04-02 17:05:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:05:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:05:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:05:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:05:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.315805
2025-04-02 17:05:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:05:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:05:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:05:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:05:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:05:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.321193
2025-04-02 17:05:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:05:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:05:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:05:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:05:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:05:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341685
2025-04-02 17:05:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:05:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:05:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:05:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:05:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.628504119308849, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_148_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.3238317571127363, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104659d90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f0c755550>]}, optimizer_kwargs={'weight_decay': 9.456849540974284e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 1.0482229490117253e-05, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:05:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:05:48 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 17:05:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:05:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:05:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:05:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:05:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:05:48 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
26.8 M    Trainable params
0         Non-trainable params
26.8 M    Total params
107.360   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:05:48 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_148_window_0/hparams.yaml
2025-04-02 17:06:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:06:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:06:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:06:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:06:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.465168
2025-04-02 17:06:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:06:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:06:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:06:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:06:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:06:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.444474
2025-04-02 17:06:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:06:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:06:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:06:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:06:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:06:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.441754
2025-04-02 17:06:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:06:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:06:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:06:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:06:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6171472644945734, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_149_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 3.56973168678006, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedcc150>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f2426c910>]}, optimizer_kwargs={'weight_decay': 8.019725997429856e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007375381471056022, 'pct_start': 0.3, 'div_factor': 25, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:06:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:06:34 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:06:34 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:06:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:06:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:06:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:06:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:06:34 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.8 M    Trainable params
0         Non-trainable params
11.8 M    Total params
47.033    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 17:06:34 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_149_window_0/hparams.yaml
2025-04-02 17:07:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:07:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:07:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:07:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:07:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301772
2025-04-02 17:07:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:07:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:07:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:07:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:07:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:07:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31476
2025-04-02 17:07:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:07:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:07:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:07:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:07:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:07:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34276
2025-04-02 17:07:21 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:07:21 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:07:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:07:21 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:07:21 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6422600536225983, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_150_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.2995156489946407, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feed63d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefd91d0>]}, optimizer_kwargs={'weight_decay': 0.07017055177540432}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000551154211199883, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:07:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:07:21 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:07:21 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:07:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:07:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:07:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:07:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:07:21 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:07:22 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_150_window_0/hparams.yaml
2025-04-02 17:08:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:08:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29875
2025-04-02 17:08:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:08:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:08:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31454
2025-04-02 17:08:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:08:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:08:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33973
2025-04-02 17:08:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:08:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:08:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:08:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:08:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5888114117623773, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_151_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.627365618926742, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ad9e90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103cba450>]}, optimizer_kwargs={'weight_decay': 0.00012956512524691987}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009957447438696105, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:08:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:08:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:08:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:08:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:08:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:08:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_151_window_0/hparams.yaml
2025-04-02 17:08:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:08:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295031
2025-04-02 17:08:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:08:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:08:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311171
2025-04-02 17:08:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:08:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:08:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:08:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:08:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:09:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.345629
2025-04-02 17:09:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:09:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:09:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:09:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:09:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6277260294653796, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_152_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.6383878758933896, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81046283d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039eb150>]}, optimizer_kwargs={'weight_decay': 0.00010408985533203884}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008661565581946204, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:09:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:09:03 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:09:03 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:09:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:09:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:09:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:09:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:09:03 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:09:03 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_152_window_0/hparams.yaml
2025-04-02 17:09:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:09:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:09:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:09:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:09:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292343
2025-04-02 17:09:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:09:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:09:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:09:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:09:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:09:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309661
2025-04-02 17:09:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:09:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:09:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:09:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:09:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:09:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341695
2025-04-02 17:09:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:09:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:09:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:09:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:09:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6314288841413466, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_153_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.5617482271968361, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed03f90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810478a150>]}, optimizer_kwargs={'weight_decay': 0.00010913037636076427}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 7.565624381106793e-07, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:09:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:09:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:09:54 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:09:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:09:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:09:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:09:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:09:54 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:09:54 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_153_window_0/hparams.yaml
2025-04-02 17:09:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:09:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:09:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:09:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.354467
2025-04-02 17:10:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:10:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.39267
2025-04-02 17:10:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:10:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.399614
2025-04-02 17:10:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:10:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:10:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:10:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:10:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6763292497815829, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_154_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 4.491952154715891, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047b8f50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee7b110>]}, optimizer_kwargs={'weight_decay': 5.145429775330992e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006807191860250753, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:10:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:10:08 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:10:08 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:10:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:08 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:10:08 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_154_window_0/hparams.yaml
2025-04-02 17:10:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294131
2025-04-02 17:10:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:10:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31271
2025-04-02 17:10:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:10:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338302
2025-04-02 17:10:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:10:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:10:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:10:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:10:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6773451420947808, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_155_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 8.339188949112108, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d7d390>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee3c990>]}, optimizer_kwargs={'weight_decay': 6.002167692863477e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006534901558436044, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:10:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:10:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:10:54 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:10:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:10:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:10:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:10:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:10:54 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:10:54 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_155_window_0/hparams.yaml
2025-04-02 17:11:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:11:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:11:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:11:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:11:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295682
2025-04-02 17:11:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:11:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:11:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:11:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:11:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:11:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314161
2025-04-02 17:11:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:11:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:11:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:11:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:11:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:11:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338199
2025-04-02 17:11:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:11:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:11:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:11:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:11:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=64, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.693087295260576, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_156_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.7243277649102007, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c6ec90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ba40d0>]}, optimizer_kwargs={'weight_decay': 0.00011060664246544977}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000844402530531372, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:11:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:11:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:11:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:11:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:11:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:11:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:11:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:11:41 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 460 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.1 M    Trainable params
0         Non-trainable params
25.1 M    Total params
100.443   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:11:41 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_156_window_0/hparams.yaml
2025-04-02 17:12:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.313951
2025-04-02 17:12:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:12:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31852
2025-04-02 17:12:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:12:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342072
2025-04-02 17:12:19 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:12:19 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:12:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:12:19 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:12:19 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6585754922575902, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_157_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.256361398124951, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feeeb110>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d7d390>]}, optimizer_kwargs={'weight_decay': 0.0001945548124769934}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 7.476697927186704e-06, 'pct_start': 0.3, 'div_factor': 45, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:12:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:12:19 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:12:20 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:12:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:20 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:12:20 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_157_window_0/hparams.yaml
2025-04-02 17:12:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.346725
2025-04-02 17:12:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:12:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.383868
2025-04-02 17:12:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:12:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.388165
2025-04-02 17:12:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:12:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:12:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:12:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:12:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.6711033542545775, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_158_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5693528648025589, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81043149d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef6ce10>]}, optimizer_kwargs={'weight_decay': 5.049017002334504e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0006559821529236146, 'pct_start': 0.3, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:12:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:12:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:12:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:12:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:12:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:12:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:12:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:12:52 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.780    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:12:52 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_158_window_0/hparams.yaml
2025-04-02 17:13:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:13:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:13:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:13:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:13:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.30611
2025-04-02 17:13:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:13:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:13:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:13:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:13:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:13:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.328627
2025-04-02 17:13:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:13:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:13:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:13:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:13:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:13:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.350354
2025-04-02 17:13:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:13:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:13:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:13:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:13:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.5995478299121524, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_159_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 2.2676159079300047, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ce8490>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103a89850>]}, optimizer_kwargs={'weight_decay': 0.0006565019135706055}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0005535935563745729, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:13:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:13:22 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:13:23 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:13:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:13:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:13:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:13:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:13:23 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:13:23 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_159_window_0/hparams.yaml
2025-04-02 17:13:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:13:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:13:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:13:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296459
2025-04-02 17:14:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:14:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.316803
2025-04-02 17:14:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:14:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341059
2025-04-02 17:14:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:14:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:14:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:14:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:14:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.6132298686622151, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_160_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 5.1452507674502925, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fede9690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedea010>]}, optimizer_kwargs={'weight_decay': 0.0004565754021446234}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 4.5366265019318535e-05, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:14:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:14:07 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:14:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:14:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:07 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
99.811    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:14:07 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_160_window_0/hparams.yaml
2025-04-02 17:14:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.332174
2025-04-02 17:14:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:14:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.379231
2025-04-02 17:14:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:14:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.404725
2025-04-02 17:14:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:14:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:14:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:14:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:14:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.64815028667306, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_161_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6810489428622251, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038e5b50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e22950>]}, optimizer_kwargs={'weight_decay': 7.221469482702278e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007580781677374533, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:14:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:14:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:14:54 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:14:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:14:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:14:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:14:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:14:54 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:14:54 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_161_window_0/hparams.yaml
2025-04-02 17:15:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:15:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:15:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:15:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:15:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292812
2025-04-02 17:15:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:15:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:15:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:15:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:15:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:15:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311121
2025-04-02 17:15:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:15:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:15:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:15:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:15:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:15:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339883
2025-04-02 17:15:39 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:15:39 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:15:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:15:39 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:15:39 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6489050978665882, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_162_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8375824137165212, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7ee5f39110>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81038f59d0>]}, optimizer_kwargs={'weight_decay': 0.00010012925114142511}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008510970878754844, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:15:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:15:39 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:15:39 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:15:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:15:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:15:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:15:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:15:39 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:15:39 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_162_window_0/hparams.yaml
2025-04-02 17:16:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:16:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:16:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:16:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:16:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292334
2025-04-02 17:16:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:16:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:16:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:16:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:16:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:16:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310076
2025-04-02 17:16:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:16:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:16:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:16:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:16:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:16:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341129
2025-04-02 17:16:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:16:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:16:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:16:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:16:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6540895393456919, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_163_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6786459605721478, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f0c2f2ed0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ca5f90>]}, optimizer_kwargs={'weight_decay': 7.402658360517589e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008742612095919639, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:16:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:16:24 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:16:24 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:16:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:16:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:16:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:16:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:16:24 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:16:24 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_163_window_0/hparams.yaml
2025-04-02 17:17:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292379
2025-04-02 17:17:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:17:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310064
2025-04-02 17:17:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:17:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34075
2025-04-02 17:17:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:17:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:17:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:17:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:17:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6553291844052981, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_164_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7139613310185997, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d79690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810471e1d0>]}, optimizer_kwargs={'weight_decay': 8.636878188217582e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008608422675223079, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:17:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:17:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:17:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:17:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:17:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_164_window_0/hparams.yaml
2025-04-02 17:17:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291939
2025-04-02 17:17:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:17:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310487
2025-04-02 17:17:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:17:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339833
2025-04-02 17:17:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:17:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:17:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:17:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:17:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6534661233852649, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_165_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7026743917151506, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038a17d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef82a10>]}, optimizer_kwargs={'weight_decay': 8.704546754531108e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008926629509057992, 'pct_start': 0.3, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:17:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:17:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:17:51 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:17:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:17:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:17:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:17:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:17:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:17:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_165_window_0/hparams.yaml
2025-04-02 17:18:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:18:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:18:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:18:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:18:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292267
2025-04-02 17:18:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:18:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:18:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:18:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:18:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:18:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310223
2025-04-02 17:18:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:18:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:18:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:18:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:18:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:18:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342054
2025-04-02 17:18:37 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:18:37 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:18:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:18:37 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:18:37 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6468332345191941, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_166_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6782150811291213, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bf7790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103da4e90>]}, optimizer_kwargs={'weight_decay': 7.955998828004304e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000996844964184994, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:18:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:18:37 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:18:37 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:18:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:18:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:18:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:18:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:18:37 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:18:37 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_166_window_0/hparams.yaml
2025-04-02 17:19:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:19:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:19:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:19:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:19:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292612
2025-04-02 17:19:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:19:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:19:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:19:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:19:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:19:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309148
2025-04-02 17:19:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:19:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:19:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:19:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:19:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:19:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339303
2025-04-02 17:19:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:19:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:19:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:19:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:19:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6574045404295402, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_167_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.687998850987675, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81046b4d10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d27510>]}, optimizer_kwargs={'weight_decay': 7.261537698565108e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009717681052478742, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:19:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:19:23 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:19:23 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:19:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:19:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:19:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:19:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:19:23 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:19:23 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_167_window_0/hparams.yaml
2025-04-02 17:19:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:19:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:19:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:19:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:20:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291953
2025-04-02 17:20:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:20:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:20:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:20:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:20:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:20:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309858
2025-04-02 17:20:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:20:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:20:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:20:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:20:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:20:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339605
2025-04-02 17:20:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:20:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:20:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:20:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:20:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6553307198955427, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_168_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6475139884295806, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f49790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f47f10>]}, optimizer_kwargs={'weight_decay': 7.659272723995505e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0009914571623246783, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': False})
2025-04-02 17:20:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:20:06 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 17:20:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:20:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:20:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:20:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:20:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:20:07 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.145   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:20:07 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_168_window_0/hparams.yaml
2025-04-02 17:20:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:20:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:20:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:20:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:20:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.508245
2025-04-02 17:20:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:20:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:20:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:20:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:20:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:20:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.488896
2025-04-02 17:20:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:20:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:20:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:20:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:20:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:21:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.482401
2025-04-02 17:21:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:21:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:21:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:21:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:21:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.6985493524589226, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_169_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5221012511540041, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103933650>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103db2550>]}, optimizer_kwargs={'weight_decay': 6.49512310533479e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0008777385124181266, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 17:21:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:21:01 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:21:01 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:21:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:21:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:21:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:21:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:21:01 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.7 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
99.852    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:21:01 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_169_window_0/hparams.yaml
2025-04-02 17:21:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:21:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:21:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:21:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:21:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.321462
2025-04-02 17:21:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:21:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:21:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:21:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:21:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:21:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.328275
2025-04-02 17:21:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:21:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:21:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:21:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:21:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:21:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.358945
2025-04-02 17:21:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:21:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:21:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:21:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:21:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6508652543012938, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_170_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8581748235556431, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f4d910>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feef72d0>]}, optimizer_kwargs={'weight_decay': 9.077455842515671e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.000869109048020998, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:21:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:21:26 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 17:21:26 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:21:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:21:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:21:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:21:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:21:26 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:21:26 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_170_window_0/hparams.yaml
2025-04-02 17:21:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:21:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:21:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:21:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.37183
2025-04-02 17:22:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:22:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.356579
2025-04-02 17:22:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:22:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.373897
2025-04-02 17:22:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:22:07 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:22:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:22:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:22:07 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6604164329715041, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_171_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6828268350331043, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefc7850>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c32790>]}, optimizer_kwargs={'weight_decay': 7.888814065049697e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009928994770772527, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:22:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:22:07 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:22:07 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:22:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:08 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:22:08 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_171_window_0/hparams.yaml
2025-04-02 17:22:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291812
2025-04-02 17:22:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:22:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309948
2025-04-02 17:22:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:22:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339786
2025-04-02 17:22:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:22:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:22:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:22:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:22:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6608481451334846, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_172_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6081449609090903, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103f4f690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104766c10>]}, optimizer_kwargs={'weight_decay': 7.545481959576192e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008848531701998573, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:22:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:22:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:22:50 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:22:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:22:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:22:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:22:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:22:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:22:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_172_window_0/hparams.yaml
2025-04-02 17:23:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:23:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:23:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:23:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:23:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292384
2025-04-02 17:23:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:23:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:23:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:23:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:23:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:23:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311069
2025-04-02 17:23:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:23:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:23:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:23:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:23:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:23:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339202
2025-04-02 17:23:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:23:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:23:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:23:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:23:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6836825664733932, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_173_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7041694992772032, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038f4c90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ea8890>]}, optimizer_kwargs={'weight_decay': 7.838110634981893e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008299954492268322, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:23:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:23:30 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:23:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:23:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:23:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:23:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:23:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:23:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:23:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_173_window_0/hparams.yaml
2025-04-02 17:24:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29505
2025-04-02 17:24:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:24:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313987
2025-04-02 17:24:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:24:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.337447
2025-04-02 17:24:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:24:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:24:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:24:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:24:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.666229561311567, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_174_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5854767650254951, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810433ce90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b1a450>]}, optimizer_kwargs={'weight_decay': 9.698101821043111e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007742753769829155, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:24:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:24:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:24:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:24:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:24:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_174_window_0/hparams.yaml
2025-04-02 17:24:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295378
2025-04-02 17:24:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:24:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312617
2025-04-02 17:24:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:24:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338641
2025-04-02 17:24:55 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:24:55 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:24:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:24:55 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:24:55 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6584138707632262, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_175_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6430226583456657, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81044d7410>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103947bd0>]}, optimizer_kwargs={'weight_decay': 6.190423727253113e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009751510984081236, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:24:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:24:55 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:24:55 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:24:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:24:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:24:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:24:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:24:55 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:24:56 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_175_window_0/hparams.yaml
2025-04-02 17:25:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:25:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:25:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:25:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:25:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292156
2025-04-02 17:25:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:25:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:25:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:25:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:25:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:25:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309771
2025-04-02 17:25:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:25:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:25:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:25:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:25:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:25:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339027
2025-04-02 17:25:43 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:25:43 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:25:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:25:43 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:25:43 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.661018591820748, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_176_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7951234256621231, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810469cf10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810466a490>]}, optimizer_kwargs={'weight_decay': 5.953536493627074e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000965143825045637, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:25:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:25:43 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:25:43 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:25:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:25:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:25:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:25:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:25:43 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:25:43 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_176_window_0/hparams.yaml
2025-04-02 17:26:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291624
2025-04-02 17:26:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:26:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310081
2025-04-02 17:26:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:26:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339109
2025-04-02 17:26:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:26:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:26:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:26:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:26:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6644848580612277, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_177_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7845020976468794, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038e7990>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81038e6cd0>]}, optimizer_kwargs={'weight_decay': 6.888671516822286e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009750307875344069, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:26:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:26:25 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:26:25 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:26:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:25 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.414    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:26:25 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_177_window_0/hparams.yaml
2025-04-02 17:26:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.30446
2025-04-02 17:26:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:26:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.322834
2025-04-02 17:26:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:26:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:26:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:26:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:26:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:26:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.354203
2025-04-02 17:26:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:26:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:26:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:26:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:26:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6367396146603096, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_178_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.622444779588695, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d817d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c83410>]}, optimizer_kwargs={'weight_decay': 6.022648202370482e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009986512801466157, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:26:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:26:59 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:27:00 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:27:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:27:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:27:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:27:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:27:00 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:27:00 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_178_window_0/hparams.yaml
2025-04-02 17:27:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:27:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:27:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:27:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:27:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292392
2025-04-02 17:27:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:27:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:27:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:27:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:27:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:27:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309718
2025-04-02 17:27:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:27:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:27:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:27:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:27:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:27:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340828
2025-04-02 17:27:46 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:27:46 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:27:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:27:46 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:27:46 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.639388159534697, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_179_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6212919145429819, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810438b7d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d7a6d0>]}, optimizer_kwargs={'weight_decay': 6.194051814292035e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007584692274709363, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:27:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:27:46 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:27:46 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:27:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:27:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:27:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:27:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:27:46 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:27:46 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_179_window_0/hparams.yaml
2025-04-02 17:28:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:28:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:28:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:28:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:28:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29639
2025-04-02 17:28:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:28:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:28:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:28:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:28:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:28:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311991
2025-04-02 17:28:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:28:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:28:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:28:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:28:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:28:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339305
2025-04-02 17:28:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:28:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:28:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:28:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:28:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6804058867457139, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_180_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.4938574819714169, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d99350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103931450>]}, optimizer_kwargs={'weight_decay': 5.8522038810405315e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008716389431905118, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 17:28:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:28:32 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:28:32 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:28:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:28:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:28:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:28:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:28:32 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 115 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.944    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:28:32 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_180_window_0/hparams.yaml
2025-04-02 17:29:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:29:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:29:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:29:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:29:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.298524
2025-04-02 17:29:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:29:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:29:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:29:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:29:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:29:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313867
2025-04-02 17:29:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:29:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:29:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:29:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:29:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:29:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.354506
2025-04-02 17:29:20 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:29:20 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:29:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:29:20 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:29:20 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6409090552488804, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_181_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8350298527161013, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d7c590>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee8e710>]}, optimizer_kwargs={'weight_decay': 7.263151789502084e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009812284958508476, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:29:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:29:20 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:29:20 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:29:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:29:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:29:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:29:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:29:20 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:29:20 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_181_window_0/hparams.yaml
2025-04-02 17:29:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:29:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:29:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:29:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:29:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.29358
2025-04-02 17:29:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:29:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:29:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:29:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:29:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.308531
2025-04-02 17:30:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:30:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:30:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:30:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:30:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340674
2025-04-02 17:30:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:30:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:30:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:30:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:30:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6358053895672212, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_182_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8632973575840387, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104325950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039ea050>]}, optimizer_kwargs={'weight_decay': 7.316514636503395e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009809305064678482, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:30:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:30:05 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:30:05 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:30:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:30:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:30:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:30:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:05 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:30:05 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_182_window_0/hparams.yaml
2025-04-02 17:30:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:30:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:30:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:30:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291982
2025-04-02 17:30:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:30:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:30:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:30:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:30:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309743
2025-04-02 17:30:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:30:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:30:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:30:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:30:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340263
2025-04-02 17:30:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:30:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:30:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:30:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:30:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6333380861001986, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_183_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8890108167190259, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed397d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039fe990>]}, optimizer_kwargs={'weight_decay': 7.003055943672221e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009842236207714362, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:30:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:30:48 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:30:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:30:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:30:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:30:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:30:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:30:48 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:30:48 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_183_window_0/hparams.yaml
2025-04-02 17:31:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:31:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:31:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:31:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:31:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291849
2025-04-02 17:31:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:31:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:31:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:31:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:31:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:31:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309793
2025-04-02 17:31:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:31:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:31:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:31:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:31:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:31:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339739
2025-04-02 17:31:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:31:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:31:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:31:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:31:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6325008179881724, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_184_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8880836593265724, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103de6490>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed51ed0>]}, optimizer_kwargs={'weight_decay': 5.651871869788012e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000986132852482109, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:31:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:31:31 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:31:31 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:31:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:31:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:31:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:31:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:31:31 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:31:31 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_184_window_0/hparams.yaml
2025-04-02 17:32:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:32:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:32:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:32:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:32:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291874
2025-04-02 17:32:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:32:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:32:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:32:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:32:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:32:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310207
2025-04-02 17:32:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:32:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:32:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:32:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:32:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:32:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340356
2025-04-02 17:32:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:32:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:32:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:32:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:32:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6336638099226652, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_185_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.948304908863287, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d997d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedd8110>]}, optimizer_kwargs={'weight_decay': 6.129705896039755e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009831781809436365, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:32:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:32:14 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:32:14 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:32:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:32:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:32:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:32:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:32:14 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:32:14 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_185_window_0/hparams.yaml
2025-04-02 17:32:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:32:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:32:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:32:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295407
2025-04-02 17:33:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:33:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.307837
2025-04-02 17:33:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:33:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338567
2025-04-02 17:33:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:33:06 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:33:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:33:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:33:06 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6665492572245233, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_186_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8318484211823016, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103bb17d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103bb0450>]}, optimizer_kwargs={'weight_decay': 5.70008981903073e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000954060038662363, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:33:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:33:06 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:33:06 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:33:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:06 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:33:06 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_186_window_0/hparams.yaml
2025-04-02 17:33:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292616
2025-04-02 17:33:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:33:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310278
2025-04-02 17:33:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:33:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338821
2025-04-02 17:33:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:33:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:33:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:33:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:33:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=64, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6645065285887077, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_187_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0503788310765716, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b9b8d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103eaa950>]}, optimizer_kwargs={'weight_decay': 5.663183576192282e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0009657966405626979, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:33:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:33:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 17:33:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:33:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:33:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:33:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:33:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:33:52 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 460 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
27.0 M    Trainable params
0         Non-trainable params
27.0 M    Total params
108.013   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:33:52 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_187_window_0/hparams.yaml
2025-04-02 17:34:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:34:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:34:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:34:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:34:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.429084
2025-04-02 17:34:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:34:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:34:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:34:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:34:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:34:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.407144
2025-04-02 17:34:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:34:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:34:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:34:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:34:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:34:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.406416
2025-04-02 17:34:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:34:31 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:34:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:34:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:34:31 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6356265530523548, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_188_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9377526111725278, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee4de90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046aeb10>]}, optimizer_kwargs={'weight_decay': 5.6088327161416775e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009957062430059407, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:34:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:34:31 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:34:31 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:34:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:34:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:34:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:34:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:34:31 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:34:31 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_188_window_0/hparams.yaml
2025-04-02 17:35:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291733
2025-04-02 17:35:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:35:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309682
2025-04-02 17:35:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:35:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340506
2025-04-02 17:35:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:35:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:35:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:35:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:35:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6377881119720121, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_189_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8808688150940417, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810466be10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104669050>]}, optimizer_kwargs={'weight_decay': 5.000709143051864e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009683622898885916, 'pct_start': 0.25, 'div_factor': 35, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:35:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:35:14 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:35:14 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:35:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:14 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:35:14 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_189_window_0/hparams.yaml
2025-04-02 17:35:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292183
2025-04-02 17:35:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:35:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310137
2025-04-02 17:35:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:35:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339693
2025-04-02 17:35:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:35:59 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:35:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:35:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:35:59 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.637648459971418, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_190_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9319268541212036, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039d6950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104537c50>]}, optimizer_kwargs={'weight_decay': 5.097751130248898e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009732107028982302, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:35:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:35:59 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:35:59 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:35:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:35:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:35:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:35:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:35:59 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:35:59 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_190_window_0/hparams.yaml
2025-04-02 17:36:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:36:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:36:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:36:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:36:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291709
2025-04-02 17:36:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:36:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:36:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:36:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:36:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:36:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309796
2025-04-02 17:36:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:36:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:36:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:36:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:36:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:36:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339769
2025-04-02 17:36:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:36:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:36:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:36:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:36:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6389069352387957, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_191_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9184546099375868, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104504f90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e5b150>]}, optimizer_kwargs={'weight_decay': 5.041080750169555e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009679425615876302, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:36:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:36:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:36:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:36:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:36:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:36:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:36:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:36:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:36:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_191_window_0/hparams.yaml
2025-04-02 17:37:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:37:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:37:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:37:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:37:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292453
2025-04-02 17:37:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:37:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:37:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:37:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:37:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:37:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309631
2025-04-02 17:37:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:37:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:37:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:37:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:37:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:37:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339953
2025-04-02 17:37:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:37:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:37:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:37:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:37:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6357212824546005, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_192_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9344289830189826, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104569790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103cbbc50>]}, optimizer_kwargs={'weight_decay': 5.155421379463283e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009943819975754662, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:37:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:37:32 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:37:32 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:37:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:37:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:37:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:37:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:37:32 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:37:32 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_192_window_0/hparams.yaml
2025-04-02 17:38:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:38:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291675
2025-04-02 17:38:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:38:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:38:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309926
2025-04-02 17:38:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:38:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:38:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34041
2025-04-02 17:38:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:38:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:38:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:38:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:38:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6331218405092712, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_193_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9365657028146225, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b7f550>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d2c610>]}, optimizer_kwargs={'weight_decay': 5.13233520432099e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009940161634867356, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:38:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:38:17 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:38:17 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:38:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:38:17 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:38:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_193_window_0/hparams.yaml
2025-04-02 17:38:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:38:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292627
2025-04-02 17:38:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:38:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:38:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.308913
2025-04-02 17:38:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:38:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:38:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:38:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:38:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:39:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339502
2025-04-02 17:39:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:39:01 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:39:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:39:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:39:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6739676865675337, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_194_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9239305036047489, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feea9690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80feeab590>]}, optimizer_kwargs={'weight_decay': 5.109176024809634e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009806820596308143, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:39:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:39:01 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:39:01 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:39:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:39:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:39:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:39:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:39:01 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:39:01 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_194_window_0/hparams.yaml
2025-04-02 17:39:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:39:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:39:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:39:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:39:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291979
2025-04-02 17:39:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:39:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:39:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:39:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310292
2025-04-02 17:39:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:39:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:39:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:39:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33947
2025-04-02 17:39:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:39:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:39:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:39:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.684466301817054, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_195_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.939987738723614, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefb17d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefb1990>]}, optimizer_kwargs={'weight_decay': 5.3358397245215576e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007257393846842896, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:39:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:39:47 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:39:47 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:39:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:39:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:39:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:39:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:39:47 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:39:47 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_195_window_0/hparams.yaml
2025-04-02 17:40:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:40:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:40:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:40:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:40:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296857
2025-04-02 17:40:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:40:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:40:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:40:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315768
2025-04-02 17:40:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:40:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:40:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:40:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:40:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:40:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339023
2025-04-02 17:40:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:40:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:40:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:40:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:40:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6678967984221029, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_196_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.015589444141577, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038a1690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039a0110>]}, optimizer_kwargs={'weight_decay': 5.0875443285631357e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009951257153761066, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:40:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:40:27 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:40:27 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:40:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:40:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:40:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:40:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:40:27 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:40:27 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_196_window_0/hparams.yaml
2025-04-02 17:41:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291437
2025-04-02 17:41:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:41:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309733
2025-04-02 17:41:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:41:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33945
2025-04-02 17:41:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:41:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:41:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:41:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:41:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6715346192886614, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_197_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0354809592748278, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104780310>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee7a590>]}, optimizer_kwargs={'weight_decay': 5.162799864839427e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009956718038522563, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:41:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:41:12 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:41:12 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:41:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:41:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_197_window_0/hparams.yaml
2025-04-02 17:41:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291878
2025-04-02 17:41:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:41:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310574
2025-04-02 17:41:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:41:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339546
2025-04-02 17:41:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:41:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:41:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:41:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:41:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6704395952116097, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_198_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0595693445321348, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104672cd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810470e790>]}, optimizer_kwargs={'weight_decay': 5.2674121053947625e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009959427792142694, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:41:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:41:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:41:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:41:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:41:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:41:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:41:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:41:53 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:41:53 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_198_window_0/hparams.yaml
2025-04-02 17:42:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:42:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292216
2025-04-02 17:42:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:42:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:42:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31053
2025-04-02 17:42:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:42:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:42:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33912
2025-04-02 17:42:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:42:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:42:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:42:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:42:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6709255401210099, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_199_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0106375636053515, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef82050>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e5b710>]}, optimizer_kwargs={'weight_decay': 5.005384075275119e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0007420560047484374, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:42:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:42:34 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:42:34 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:42:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:42:34 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:42:34 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_199_window_0/hparams.yaml
2025-04-02 17:42:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:42:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.306692
2025-04-02 17:42:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:42:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:42:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.324498
2025-04-02 17:42:59 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:42:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:42:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:42:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:42:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:43:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.345536
2025-04-02 17:43:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:43:03 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:43:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:43:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:43:03 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.6896264680458907, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_200_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0547878438993794, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104419790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef50e10>]}, optimizer_kwargs={'weight_decay': 6.196927053948386e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000668322467904493, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': False})
2025-04-02 17:43:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:43:03 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:43:03 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:43:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:43:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:43:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:43:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:43:03 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.780    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:43:03 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_200_window_0/hparams.yaml
2025-04-02 17:43:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:43:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:43:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:43:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:43:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299064
2025-04-02 17:43:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:43:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:43:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:43:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:43:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:43:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.318947
2025-04-02 17:43:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:43:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:43:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:43:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:43:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:43:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.342783
2025-04-02 17:43:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:43:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:43:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:43:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:43:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6743389379313018, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_201_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9110312145809878, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81047b8f50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f4cd10>]}, optimizer_kwargs={'weight_decay': 6.339191672974252e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000985264077159238, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:43:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:43:53 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:43:53 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:43:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:43:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:43:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:43:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:43:53 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:43:53 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_201_window_0/hparams.yaml
2025-04-02 17:44:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:44:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:44:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:44:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:44:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291415
2025-04-02 17:44:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:44:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:44:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:44:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:44:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:44:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310324
2025-04-02 17:44:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:44:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:44:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:44:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:44:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:44:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339644
2025-04-02 17:44:38 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:44:38 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:44:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:44:38 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:44:38 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.672507964540195, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_202_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9285499986670396, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee8cbd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104286ed0>]}, optimizer_kwargs={'weight_decay': 5.1299962634204504e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009737383604004203, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:44:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:44:38 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:44:38 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:44:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:44:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:44:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:44:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:44:38 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:44:38 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_202_window_0/hparams.yaml
2025-04-02 17:45:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:45:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:45:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:45:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:45:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293986
2025-04-02 17:45:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:45:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:45:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:45:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:45:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:45:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309273
2025-04-02 17:45:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:45:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:45:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:45:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:45:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:45:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339186
2025-04-02 17:45:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:45:27 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:45:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:45:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:45:27 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6777819119915117, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_203_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7765631392052074, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d25e50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d270d0>]}, optimizer_kwargs={'weight_decay': 6.479774132841521e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 8.796491901436381e-05, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:45:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:45:27 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:45:28 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:45:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:45:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:45:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:45:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:45:28 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:45:28 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_203_window_0/hparams.yaml
2025-04-02 17:46:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:46:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:46:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:46:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:46:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.323005
2025-04-02 17:46:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:46:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:46:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:46:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:46:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:46:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.350067
2025-04-02 17:46:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:46:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:46:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:46:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:46:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:46:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.364518
2025-04-02 17:46:13 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:46:13 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:46:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:46:13 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:46:13 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6614165756935196, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_204_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7976491870729365, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104628dd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ba29d0>]}, optimizer_kwargs={'weight_decay': 5.835766759670762e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009988044421496227, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:46:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:46:13 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:46:13 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:46:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:46:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:46:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:46:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:46:13 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:46:13 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_204_window_0/hparams.yaml
2025-04-02 17:46:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:46:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:46:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:46:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:46:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294428
2025-04-02 17:46:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:46:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:46:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:46:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:46:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309152
2025-04-02 17:47:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:47:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:47:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:47:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:47:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339608
2025-04-02 17:47:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:47:04 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:47:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:47:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:47:04 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6972822531986478, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_205_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.12490542972879, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef80e50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee31550>]}, optimizer_kwargs={'weight_decay': 5.067034663993864e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007735176569030152, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 17:47:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:47:04 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:47:05 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:47:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:47:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:47:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:47:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:05 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:47:05 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_205_window_0/hparams.yaml
2025-04-02 17:47:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:47:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:47:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:47:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.297013
2025-04-02 17:47:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:47:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:47:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:47:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:47:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31559
2025-04-02 17:47:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:47:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:47:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:47:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:47:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.337881
2025-04-02 17:47:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:47:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:47:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:47:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:47:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6652624906696396, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_206_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9340550494027653, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedd1690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103928d50>]}, optimizer_kwargs={'weight_decay': 6.679726828657528e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009975218158269881, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:47:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:47:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:47:42 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:47:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:47:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:47:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:47:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:47:42 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:47:42 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_206_window_0/hparams.yaml
2025-04-02 17:48:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291568
2025-04-02 17:48:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:48:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310303
2025-04-02 17:48:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:48:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339017
2025-04-02 17:48:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:48:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:48:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:48:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:48:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.6724200348592986, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_207_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9299036508024312, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed4fe50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103f4d4d0>]}, optimizer_kwargs={'weight_decay': 6.520292994104945e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0007852103866952321, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:48:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:48:23 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:48:23 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:48:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:23 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
99.811    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:48:23 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_207_window_0/hparams.yaml
2025-04-02 17:48:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.307427
2025-04-02 17:48:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:48:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.336467
2025-04-02 17:48:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:48:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.362444
2025-04-02 17:48:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:48:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:48:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:48:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:48:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.643524831638238, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_208_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1133968320334404, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81044859d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810392b690>]}, optimizer_kwargs={'weight_decay': 5.7819483658025146e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009849640722867934, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:48:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:48:48 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:48:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:48:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:48:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:48:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:48:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:48:48 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:48:48 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_208_window_0/hparams.yaml
2025-04-02 17:49:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:49:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:49:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:49:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:49:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291534
2025-04-02 17:49:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:49:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:49:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:49:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:49:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:49:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310151
2025-04-02 17:49:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:49:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:49:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:49:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:49:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:49:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.340245
2025-04-02 17:49:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:49:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:49:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:49:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:49:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6788879916701099, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_209_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0969510333369021, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fedcc5d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f24288b10>]}, optimizer_kwargs={'weight_decay': 6.689482945738164e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009940899945554, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:49:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:49:29 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:49:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:49:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:49:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:49:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:49:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:49:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:49:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_209_window_0/hparams.yaml
2025-04-02 17:50:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291392
2025-04-02 17:50:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:50:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309929
2025-04-02 17:50:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:50:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339061
2025-04-02 17:50:13 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:50:13 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:50:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:50:13 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:50:13 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6863409290195002, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_210_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1350240225011652, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81046b4590>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046b5d10>]}, optimizer_kwargs={'weight_decay': 6.722623455990875e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 3.30871169358859e-06, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:50:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:50:13 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:50:13 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:50:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:13 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:50:13 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_210_window_0/hparams.yaml
2025-04-02 17:50:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.354323
2025-04-02 17:50:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:50:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.393156
2025-04-02 17:50:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:50:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.3992
2025-04-02 17:50:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:50:26 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:50:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:50:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:50:26 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6684369490964698, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_211_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0360162698885211, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103990710>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103933310>]}, optimizer_kwargs={'weight_decay': 5.754637867415426e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009916608302014318, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:50:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:50:26 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:50:27 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:50:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:50:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:50:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:50:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:50:27 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:50:27 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_211_window_0/hparams.yaml
2025-04-02 17:51:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291798
2025-04-02 17:51:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:51:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309716
2025-04-02 17:51:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:51:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339829
2025-04-02 17:51:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:51:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:51:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:51:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:51:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6656701276617986, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_212_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0333363035549659, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef79350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed02ed0>]}, optimizer_kwargs={'weight_decay': 5.976652765492131e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009984223497309594, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:51:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:51:10 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:51:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:51:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:51:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_212_window_0/hparams.yaml
2025-04-02 17:51:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291805
2025-04-02 17:51:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:51:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309727
2025-04-02 17:51:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:51:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33879
2025-04-02 17:51:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:51:50 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:51:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:51:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:51:50 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6684455852293406, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_213_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.054354112614747, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee883d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810390edd0>]}, optimizer_kwargs={'weight_decay': 8.176185084199813e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008250121027358574, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:51:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:51:50 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:51:50 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:51:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:51:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:51:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:51:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:51:50 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:51:50 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_213_window_0/hparams.yaml
2025-04-02 17:52:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:52:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:52:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:52:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:52:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293196
2025-04-02 17:52:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:52:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:52:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:52:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:52:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:52:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312588
2025-04-02 17:52:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:52:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:52:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:52:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:52:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:52:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339916
2025-04-02 17:52:35 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:52:35 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:52:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:52:35 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:52:35 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6989409665882499, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_214_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1001590683985718, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81043a2950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103a6ead0>]}, optimizer_kwargs={'weight_decay': 6.013144536711683e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007601230506826069, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:52:35 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:52:35 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:52:36 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:52:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:52:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:52:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:52:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:52:36 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:52:36 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_214_window_0/hparams.yaml
2025-04-02 17:53:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.295955
2025-04-02 17:53:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:53:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315254
2025-04-02 17:53:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:53:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338266
2025-04-02 17:53:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:53:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:53:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:53:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:53:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6763708421117353, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_215_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.223147258566224, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d04650>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d07650>]}, optimizer_kwargs={'weight_decay': 6.986087893713793e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0008377640608857902, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:53:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:53:18 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 17:53:18 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:53:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:18 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 27.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
27.8 M    Trainable params
0         Non-trainable params
27.8 M    Total params
111.145   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:53:18 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_215_window_0/hparams.yaml
2025-04-02 17:53:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.423085
2025-04-02 17:53:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.411852
2025-04-02 17:53:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:53:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.411644
2025-04-02 17:53:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:53:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:53:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:53:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:53:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.6602700493478173, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_216_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.796235521420553, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103b58890>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d6ac50>]}, optimizer_kwargs={'weight_decay': 6.1026438300416924e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007025316970888004, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:53:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:53:56 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:53:56 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:53:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:53:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:53:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:53:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:53:56 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.7 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
99.852    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:53:56 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_216_window_0/hparams.yaml
2025-04-02 17:54:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:54:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:54:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:54:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:54:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.303669
2025-04-02 17:54:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:54:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:54:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:54:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:54:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:54:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.316242
2025-04-02 17:54:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:54:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:54:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:54:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:54:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:54:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.354301
2025-04-02 17:54:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:54:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:54:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:54:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:54:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6812816827475119, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_217_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0065598671754532, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81038d6650>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103af6690>]}, optimizer_kwargs={'weight_decay': 8.003597298010427e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009922533736136047, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:54:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:54:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:54:45 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:54:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:54:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:54:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:54:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:54:45 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.414    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:54:45 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_217_window_0/hparams.yaml
2025-04-02 17:55:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:55:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:55:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:55:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:55:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.304124
2025-04-02 17:55:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:55:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:55:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:55:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:55:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:55:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.321566
2025-04-02 17:55:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:55:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:55:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:55:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:55:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:55:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.35426
2025-04-02 17:55:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:55:22 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:55:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:55:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:55:22 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6613338805674354, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_218_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8240315278580953, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104778f50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810477a6d0>]}, optimizer_kwargs={'weight_decay': 6.818637642632796e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008542949562378473, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:55:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:55:22 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:55:22 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:55:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:55:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:55:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:55:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:55:22 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:55:22 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_218_window_0/hparams.yaml
2025-04-02 17:55:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:55:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:55:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:55:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291774
2025-04-02 17:56:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:56:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312884
2025-04-02 17:56:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:56:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339772
2025-04-02 17:56:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:56:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:56:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:56:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:56:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6899591441442141, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_219_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.999226618990365, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefa9690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f24288150>]}, optimizer_kwargs={'weight_decay': 5.982033559583707e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.000655896460271786, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:56:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:56:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 17:56:09 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:56:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:09 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:56:09 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_219_window_0/hparams.yaml
2025-04-02 17:56:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.373638
2025-04-02 17:56:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:56:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.363366
2025-04-02 17:56:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:56:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.379098
2025-04-02 17:56:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:56:54 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:56:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:56:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:56:54 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.651633161105477, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_220_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7565017838707861, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104205450>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f65810>]}, optimizer_kwargs={'weight_decay': 8.30119101585604e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009959247702652455, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:56:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:56:54 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:56:55 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:56:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:56:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:56:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:56:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:56:55 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:56:55 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_220_window_0/hparams.yaml
2025-04-02 17:57:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:57:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:57:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:57:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:57:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.293755
2025-04-02 17:57:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:57:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:57:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:57:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:57:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:57:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310422
2025-04-02 17:57:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:57:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:57:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:57:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:57:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:57:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339788
2025-04-02 17:57:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:57:42 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:57:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:57:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:57:42 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=3, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6489544150150447, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_221_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9317706580949362, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed4dc90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c31bd0>]}, optimizer_kwargs={'weight_decay': 5.515787376980638e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008572059782965828, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:57:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:57:42 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:57:43 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:57:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:57:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:57:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:57:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:57:43 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 1.9 M  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
26.5 M    Trainable params
0         Non-trainable params
26.5 M    Total params
106.102   Total estimated model params size (MB)
81        Modules in train mode
0         Modules in eval mode
2025-04-02 17:57:43 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_221_window_0/hparams.yaml
2025-04-02 17:58:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:58:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:58:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:58:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:58:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300941
2025-04-02 17:58:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:58:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:58:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:58:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:58:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:58:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315077
2025-04-02 17:58:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:58:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:58:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:58:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:58:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:58:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.336639
2025-04-02 17:58:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:58:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:58:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:58:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:58:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6722075581262937, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_222_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1749532965638991, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810450d750>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee61b10>]}, optimizer_kwargs={'weight_decay': 6.917377014011272e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009968937728218627, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:58:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:58:25 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:58:25 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:58:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:58:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:58:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:58:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:58:26 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:58:26 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_222_window_0/hparams.yaml
2025-04-02 17:58:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:58:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:58:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:58:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292145
2025-04-02 17:59:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:59:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.309035
2025-04-02 17:59:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:59:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338719
2025-04-02 17:59:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:59:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:59:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:59:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:59:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6707351672555814, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_223_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1860023908670103, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefa9690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d26290>]}, optimizer_kwargs={'weight_decay': 6.924173505747794e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008474289702519771, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:59:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:59:08 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:59:08 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:59:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:08 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:59:08 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_223_window_0/hparams.yaml
2025-04-02 17:59:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.294007
2025-04-02 17:59:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 17:59:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312129
2025-04-02 17:59:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 17:59:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338542
2025-04-02 17:59:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 17:59:51 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 17:59:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 17:59:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 17:59:51 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6835752974455768, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_224_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0534177707448746, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103df9690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103dfbed0>]}, optimizer_kwargs={'weight_decay': 6.254947545144837e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007600024512569733, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 17:59:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 17:59:51 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 17:59:51 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 17:59:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 17:59:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 17:59:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 17:59:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 17:59:51 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 17:59:51 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_224_window_0/hparams.yaml
2025-04-02 18:00:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:00:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:00:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:00:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:00:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296226
2025-04-02 18:00:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:00:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:00:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:00:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:00:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:00:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315161
2025-04-02 18:00:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:00:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:00:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:00:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:00:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:00:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338132
2025-04-02 18:00:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:00:32 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:00:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:00:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:00:32 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6675397439556026, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_225_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8444998977911543, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104644210>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee8db50>]}, optimizer_kwargs={'weight_decay': 7.418245538379852e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008884940409400391, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:00:32 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:00:32 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:00:32 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:00:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:00:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:00:32 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:00:32 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:00:33 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:00:33 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_225_window_0/hparams.yaml
2025-04-02 18:01:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.302112
2025-04-02 18:01:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:01:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313053
2025-04-02 18:01:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:01:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:13 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:13 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.325536
2025-04-02 18:01:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:01:16 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:01:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:01:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:01:16 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6588917842470604, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_226_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8540044256682179, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef97250>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fefb4410>]}, optimizer_kwargs={'weight_decay': 7.539366805835049e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008513564247443384, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:01:16 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:01:16 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:01:16 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:01:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:16 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 115 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.944    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:01:16 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_226_window_0/hparams.yaml
2025-04-02 18:01:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.297261
2025-04-02 18:01:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:01:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313213
2025-04-02 18:01:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:01:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.353694
2025-04-02 18:01:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:01:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:01:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:01:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:01:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6479983041880868, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_227_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7721998741877225, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103deff50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046cc7d0>]}, optimizer_kwargs={'weight_decay': 8.538800817576759e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007143780662280539, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 18:01:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:01:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:01:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:01:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:01:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:01:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:01:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:01:52 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:01:52 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_227_window_0/hparams.yaml
2025-04-02 18:02:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:02:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:02:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:02:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:02:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.304905
2025-04-02 18:02:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:02:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:02:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:02:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:02:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:02:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313589
2025-04-02 18:02:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:02:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:02:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:02:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:02:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:02:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.331568
2025-04-02 18:02:37 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:02:37 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:02:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:02:37 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:02:37 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=2, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6672276972946368, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_228_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.2563974781599427, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103dd10d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c60690>]}, optimizer_kwargs={'weight_decay': 6.94371857993838e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009937011693017415, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:02:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:02:37 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:02:37 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:02:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:02:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:02:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:02:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:02:37 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.6 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
11.8 M    Trainable params
0         Non-trainable params
11.8 M    Total params
47.033    Total estimated model params size (MB)
57        Modules in train mode
0         Modules in eval mode
2025-04-02 18:02:37 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_228_window_0/hparams.yaml
2025-04-02 18:03:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:03:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:03:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:03:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:03:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299669
2025-04-02 18:03:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:03:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:03:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:03:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:03:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:03:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315681
2025-04-02 18:03:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:03:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:03:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:03:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:03:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:03:20 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.336503
2025-04-02 18:03:21 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:03:21 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:03:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:03:21 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:03:21 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=64, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6833154448641889, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_229_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8601136294571905, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103dd63d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d37350>]}, optimizer_kwargs={'weight_decay': 6.141310091541096e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008451902256934505, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:03:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:03:21 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:03:21 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:03:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:03:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:03:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:03:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:03:21 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 460 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.1 M    Trainable params
0         Non-trainable params
25.1 M    Total params
100.443   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:03:21 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_229_window_0/hparams.yaml
2025-04-02 18:04:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:04:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.321
2025-04-02 18:04:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:04:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:04:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.325217
2025-04-02 18:04:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:04:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:04:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.351351
2025-04-02 18:04:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:04:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:04:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:04:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:04:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6585758065230094, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_230_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7349773032096718, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d63910>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039ffb10>]}, optimizer_kwargs={'weight_decay': 8.857620454051582e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0007667261305682769, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:04:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:04:25 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 18:04:25 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:04:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:04:25 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 12.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
12.9 M    Trainable params
0         Non-trainable params
12.9 M    Total params
51.609    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:04:25 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_230_window_0/hparams.yaml
2025-04-02 18:04:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:04:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.403858
2025-04-02 18:04:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:04:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:04:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.391583
2025-04-02 18:04:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:04:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:04:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:04:57 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:04:57 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:05:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.392507
2025-04-02 18:05:00 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:05:00 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:05:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:05:00 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:05:00 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6683328029151571, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_231_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 28.007812431098046, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fef51350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104737250>]}, optimizer_kwargs={'weight_decay': 6.013752235618515e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009824639342477864, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:05:00 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:05:00 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:05:00 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:05:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:05:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:05:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:05:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:05:01 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:05:01 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_231_window_0/hparams.yaml
2025-04-02 18:05:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:05:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:05:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:05:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:05:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300841
2025-04-02 18:05:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:05:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:05:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:05:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:05:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:05:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313267
2025-04-02 18:05:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:05:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:05:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:05:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:05:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:05:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.327115
2025-04-02 18:05:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:05:40 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:05:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:05:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:05:40 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6475346559621018, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_232_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 70.19182130918972, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feddae90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ded090>]}, optimizer_kwargs={'weight_decay': 5.841956134786535e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 5.739700539208045e-05, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:05:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:05:40 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:05:40 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:05:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:05:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:05:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:05:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:05:40 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:05:40 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_232_window_0/hparams.yaml
2025-04-02 18:06:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.34267
2025-04-02 18:06:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:06:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.343103
2025-04-02 18:06:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:06:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.375116
2025-04-02 18:06:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:06:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:06:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:06:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:06:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6735661227717072, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_233_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.947995999263682, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103992d50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103dd6150>]}, optimizer_kwargs={'weight_decay': 7.395211124003877e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008697908471066312, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:06:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:06:18 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:06:18 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:06:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:18 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:06:18 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_233_window_0/hparams.yaml
2025-04-02 18:06:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300412
2025-04-02 18:06:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:06:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313179
2025-04-02 18:06:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:06:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.327033
2025-04-02 18:06:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:06:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:06:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:06:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:06:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6784438574630997, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_234_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1361736694279854, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d81690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f2426f110>]}, optimizer_kwargs={'weight_decay': 6.065015633525908e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008642339647275586, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:06:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:06:56 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:06:56 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:06:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:06:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:06:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:06:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:06:56 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:06:56 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_234_window_0/hparams.yaml
2025-04-02 18:07:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:07:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:07:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:07:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:07:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.30146
2025-04-02 18:07:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:07:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:07:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:07:33 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:07:33 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:07:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312477
2025-04-02 18:07:36 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:07:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:07:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:07:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:07:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:07:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.330055
2025-04-02 18:07:39 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:07:39 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:07:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:07:39 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:07:39 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6917977501713907, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_235_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9666604797435132, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810392d790>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ccefd0>]}, optimizer_kwargs={'weight_decay': 7.281497021290601e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 1.560005187537734e-05, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:07:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:07:39 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:07:39 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:07:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:07:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:07:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:07:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:07:39 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:07:39 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_235_window_0/hparams.yaml
2025-04-02 18:08:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.35706
2025-04-02 18:08:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:08:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.354371
2025-04-02 18:08:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:08:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:13 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.390138
2025-04-02 18:08:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:08:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:08:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:08:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:08:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6659345742638068, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_236_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9729745213192574, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104646bd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fed02190>]}, optimizer_kwargs={'weight_decay': 5.65828765486106e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008575920701746211, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:08:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:08:14 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:08:14 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:08:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:14 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:08:14 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_236_window_0/hparams.yaml
2025-04-02 18:08:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300899
2025-04-02 18:08:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:08:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312121
2025-04-02 18:08:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:08:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.328442
2025-04-02 18:08:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:08:56 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:08:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:08:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:08:56 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6662561960792347, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_237_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 26.492687222545936, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefb6090>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810465ec90>]}, optimizer_kwargs={'weight_decay': 6.863379600489583e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006875356871232168, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:08:56 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:08:56 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:08:56 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:08:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:08:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:08:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:08:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:08:56 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:08:56 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_237_window_0/hparams.yaml
2025-04-02 18:09:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:09:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:09:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:09:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:09:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.306111
2025-04-02 18:09:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:09:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:09:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:09:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:09:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:09:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315908
2025-04-02 18:09:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:09:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:09:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:09:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:09:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:09:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.325115
2025-04-02 18:09:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:09:34 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:09:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:09:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:09:34 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6749944737591923, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_238_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9681490670834074, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104537950>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81045355d0>]}, optimizer_kwargs={'weight_decay': 8.227063003989323e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008495910210994456, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:09:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:09:34 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:09:34 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:09:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:09:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:09:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:09:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:09:34 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:09:34 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_238_window_0/hparams.yaml
2025-04-02 18:10:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:10:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:10:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:10:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:10:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300688
2025-04-02 18:10:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:10:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:10:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:10:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:10:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:10:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313201
2025-04-02 18:10:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:10:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:10:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:10:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:10:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:10:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.328187
2025-04-02 18:10:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:10:12 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:10:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:10:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:10:12 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6633463584492574, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_239_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7599904732060657, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80feeda390>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d81190>]}, optimizer_kwargs={'weight_decay': 5.772359815895246e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006166570803054122, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': False})
2025-04-02 18:10:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:10:12 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:10:12 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:10:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:10:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:10:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:10:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:10:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:10:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_239_window_0/hparams.yaml
2025-04-02 18:11:08 UTC - pytorch_lightning.utilities.rank_zero - done - INFO - `Trainer.fit` stopped: `max_epochs=300` reached.
2025-04-02 18:11:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.304413
2025-04-02 18:11:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:11:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314358
2025-04-02 18:11:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:11:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.350492
2025-04-02 18:11:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:11:17 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:11:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:11:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:11:17 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6983670519512145, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_240_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8550043458642342, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103ce9350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee30050>]}, optimizer_kwargs={'weight_decay': 5.048098789199686e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0007650319438985678, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:11:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:11:17 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:11:17 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:11:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:17 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:11:17 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_240_window_0/hparams.yaml
2025-04-02 18:11:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:35 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:35 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.311571
2025-04-02 18:11:38 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:11:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31965
2025-04-02 18:11:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:11:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.335743
2025-04-02 18:11:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:11:44 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:11:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:11:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:11:44 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6498634257729333, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_241_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1654482025752737, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fefb9c90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103c47e90>]}, optimizer_kwargs={'weight_decay': 5.949122866351184e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000996027236236841, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:11:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:11:44 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:11:44 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:11:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:11:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:11:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:11:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:11:45 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:11:45 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_241_window_0/hparams.yaml
2025-04-02 18:12:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:12:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:12:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:12:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:12:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300086
2025-04-02 18:12:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:12:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:12:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:12:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:12:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:12:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31311
2025-04-02 18:12:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:12:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:12:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:12:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:12:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:12:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.332687
2025-04-02 18:12:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:12:24 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:12:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:12:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:12:24 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6588389296924024, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_242_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9979844750055149, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103e77410>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103a89cd0>]}, optimizer_kwargs={'weight_decay': 6.720240386458095e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.00087778437476039, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:12:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:12:24 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:12:24 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:12:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:12:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:12:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:12:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:12:24 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:12:24 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_242_window_0/hparams.yaml
2025-04-02 18:12:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:12:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:12:56 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:12:56 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:12:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300821
2025-04-02 18:12:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:12:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:12:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:12:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:12:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313743
2025-04-02 18:13:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:13:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:13:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:13:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:13:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33173
2025-04-02 18:13:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:13:05 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:13:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:13:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:13:05 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6815313258080296, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_243_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 18.78031221091911, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104260150>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81046ab890>]}, optimizer_kwargs={'weight_decay': 5.828381107211547e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008826411514019126, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:13:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:13:05 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:13:05 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:13:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:13:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:13:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:13:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:05 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:13:05 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_243_window_0/hparams.yaml
2025-04-02 18:13:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:13:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:13:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:13:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299972
2025-04-02 18:13:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:13:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:13:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:13:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:13:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312149
2025-04-02 18:13:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:13:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:13:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:13:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:13:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.33022
2025-04-02 18:13:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:13:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:13:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:13:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:13:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=2, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6699683588089014, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_244_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.2832704919569924, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d66350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f0e290>]}, optimizer_kwargs={'weight_decay': 7.947625099574935e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009968206998669017, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:13:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:13:47 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:13:47 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:13:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:13:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:13:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:13:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:13:47 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 288 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.2 M    Trainable params
0         Non-trainable params
12.2 M    Total params
48.616    Total estimated model params size (MB)
73        Modules in train mode
0         Modules in eval mode
2025-04-02 18:13:47 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_244_window_0/hparams.yaml
2025-04-02 18:14:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:14:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:14:16 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:14:16 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:14:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.302377
2025-04-02 18:14:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:14:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:14:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:14:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:14:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:14:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.317949
2025-04-02 18:14:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:14:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:14:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:14:22 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:14:22 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:14:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.343812
2025-04-02 18:14:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:14:25 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:14:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:14:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:14:25 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.649476393205711, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_245_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9130575035609418, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed4f450>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81038f7ad0>]}, optimizer_kwargs={'weight_decay': 6.627336095666212e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007789533704495673, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:14:25 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:14:25 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:14:25 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:14:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:14:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:14:25 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:14:25 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:14:25 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:14:25 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_245_window_0/hparams.yaml
2025-04-02 18:15:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.302353
2025-04-02 18:15:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:15:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313011
2025-04-02 18:15:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:15:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.328208
2025-04-02 18:15:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:15:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:15:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:15:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:15:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6863853609243952, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_246_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 36.59169705217232, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7f24212d50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103e59050>]}, optimizer_kwargs={'weight_decay': 5.016015755873997e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009998612882539321, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:15:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:15:10 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:15:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:15:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:15:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_246_window_0/hparams.yaml
2025-04-02 18:15:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:38 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:38 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299417
2025-04-02 18:15:41 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:15:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:41 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:41 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.313048
2025-04-02 18:15:44 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:15:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.328982
2025-04-02 18:15:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:15:47 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:15:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:15:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:15:47 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=8, use_layer_norm=True, dropout=0.6847075101468955, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_247_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6625280301597342, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee61d90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810392f310>]}, optimizer_kwargs={'weight_decay': 5.0248996961667325e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009997057389329878, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:15:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:15:47 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:15:47 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:15:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:15:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:15:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:15:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:15:47 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 9.8 K  | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.814    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:15:47 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_247_window_0/hparams.yaml
2025-04-02 18:16:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:16:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:16:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:16:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:16:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.303944
2025-04-02 18:16:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:16:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:16:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:16:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:16:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:16:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.314827
2025-04-02 18:16:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:16:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:16:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:16:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:16:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:16:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.333459
2025-04-02 18:16:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:16:30 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:16:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:16:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:16:30 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6707994984693222, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_248_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 45.13172589064341, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81041dfc90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104645810>]}, optimizer_kwargs={'weight_decay': 0.011206668585378903}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008381728732223337, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 18:16:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:16:30 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:16:30 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:16:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:16:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:16:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:16:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:16:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:16:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_248_window_0/hparams.yaml
2025-04-02 18:16:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:16:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:16:59 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:16:59 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.301202
2025-04-02 18:17:02 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:17:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.312986
2025-04-02 18:17:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:17:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.328979
2025-04-02 18:17:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:17:08 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:17:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:17:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:17:08 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6608315618235506, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_249_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 34.5586316199778, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103def6d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7f2425fd90>]}, optimizer_kwargs={'weight_decay': 9.443495853805433e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007444923245132937, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:17:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:17:08 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:17:08 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:17:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:08 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:17:08 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_249_window_0/hparams.yaml
2025-04-02 18:17:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.303362
2025-04-02 18:17:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:17:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31361
2025-04-02 18:17:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:17:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:45 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:45 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.327968
2025-04-02 18:17:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:17:48 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:17:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:17:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:17:48 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=32, use_layer_norm=True, dropout=0.6879876599413448, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_250_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=16, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 47.09211065243929, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81043155d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ccc590>]}, optimizer_kwargs={'weight_decay': 7.49573568002095e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 901, 'max_lr': 0.0008730109161249301, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:17:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:17:48 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:17:48 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:17:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:17:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:17:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:17:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:17:49 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 17.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.845    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:17:49 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_250_window_0/hparams.yaml
2025-04-02 18:18:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.30256
2025-04-02 18:18:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:18:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.340062
2025-04-02 18:18:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:18:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.357623
2025-04-02 18:18:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:18:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:18:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:18:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:18:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.676330477797638, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_251_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 10.865152392515503, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81044380d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104308510>]}, optimizer_kwargs={'weight_decay': 0.007785268830869243}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008554405769933286, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:18:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:18:11 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:18:11 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:18:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:12 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:18:12 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_251_window_0/hparams.yaml
2025-04-02 18:18:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300722
2025-04-02 18:18:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:18:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.311973
2025-04-02 18:18:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:18:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:51 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:51 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.330938
2025-04-02 18:18:55 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:18:55 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:18:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:18:55 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:18:55 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.662095283779279, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_252_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7429817055668265, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103d253d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f7ee5f0fd90>]}, optimizer_kwargs={'weight_decay': 5.723168241918572e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000682973243162028, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:18:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:18:55 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:18:55 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:18:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:18:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:18:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:18:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:18:55 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:18:55 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_252_window_0/hparams.yaml
2025-04-02 18:19:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:19:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:19:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:19:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:19:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.30605
2025-04-02 18:19:31 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:19:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:19:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:19:31 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:19:31 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:19:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315805
2025-04-02 18:19:34 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:19:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:19:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:19:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:19:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:19:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.32736
2025-04-02 18:19:37 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:19:37 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:19:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:19:37 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:19:37 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6912028665101076, use_static_covariates=True, output_chunk_length=3, input_chunk_length=12, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_253_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 39.15167117611225, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f7ee5f39110>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81047e61d0>]}, optimizer_kwargs={'weight_decay': 6.75585721186444e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.0009917553646318087, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:19:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:19:37 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 21 samples.
2025-04-02 18:19:37 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:19:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:19:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:19:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:19:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:19:38 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 13.3 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 39     | train
--------------------------------------------------------------------
13.4 M    Trainable params
0         Non-trainable params
13.4 M    Total params
53.502    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:19:38 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_253_window_0/hparams.yaml
2025-04-02 18:20:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.423382
2025-04-02 18:20:04 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:20:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:04 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:04 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.408565
2025-04-02 18:20:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:20:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.417981
2025-04-02 18:20:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:20:10 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:20:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:20:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:20:10 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.2357540136684087, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_254_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8368121813516413, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee82d50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee7afd0>]}, optimizer_kwargs={'weight_decay': 5.093677019125355e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007672320691777805, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:20:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:20:10 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:20:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:20:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:20:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_254_window_0/hparams.yaml
2025-04-02 18:20:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.304174
2025-04-02 18:20:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:20:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.316396
2025-04-02 18:20:48 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:20:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:48 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:48 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:51 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341154
2025-04-02 18:20:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:20:52 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:20:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:20:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:20:52 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=128, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=64, use_layer_norm=True, dropout=0.6751497648496366, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_255_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5600326555515082, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103a8af90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee30950>]}, optimizer_kwargs={'weight_decay': 6.492636596116229e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008621153399293719, 'pct_start': 0.25, 'div_factor': 25, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:20:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:20:52 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:20:52 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:20:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:20:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:20:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:20:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:20:52 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 1.3 K  | train
7  | future_cov_projection | _ResidualBlock   | 1.3 K  | train
8  | encoders              | Sequential       | 5.8 M  | train
9  | decoders              | Sequential       | 29.0 K | train
10 | temporal_decoder      | _ResidualBlock   | 27.7 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.476    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:20:52 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_255_window_0/hparams.yaml
2025-04-02 18:21:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:21:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:21:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:21:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:21:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.31543
2025-04-02 18:21:21 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:21:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:21:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:21:21 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:21:21 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:21:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.324556
2025-04-02 18:21:24 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:21:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:21:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:21:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:21:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:21:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.34746
2025-04-02 18:21:28 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:21:28 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:21:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:21:28 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:21:28 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.643421222086506, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_256_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.0159906466409545, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103c60690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81038f6990>]}, optimizer_kwargs={'weight_decay': 7.802052835583386e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006325503802656656, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:21:28 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:21:28 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:21:28 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:21:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:21:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:21:28 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:21:28 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:21:28 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:21:28 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_256_window_0/hparams.yaml
2025-04-02 18:22:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:00 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:00 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.299064
2025-04-02 18:22:03 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:22:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:03 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:03 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.316401
2025-04-02 18:22:06 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:22:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:06 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:06 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.3396
2025-04-02 18:22:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:22:09 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:22:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:22:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:22:09 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6997536367444408, use_static_covariates=True, output_chunk_length=3, input_chunk_length=6, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_257_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 29.09937564391157, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810433df90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f81039a0310>]}, optimizer_kwargs={'weight_decay': 9.461886841760244e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2401, 'max_lr': 0.0008589393740010368, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:22:09 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:22:09 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 27 samples.
2025-04-02 18:22:10 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:22:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:10 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 25.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 21     | train
--------------------------------------------------------------------
25.9 M    Trainable params
0         Non-trainable params
25.9 M    Total params
103.575   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:22:10 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_257_window_0/hparams.yaml
2025-04-02 18:22:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.364168
2025-04-02 18:22:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:22:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.365117
2025-04-02 18:22:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:22:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.3759
2025-04-02 18:22:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:22:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:22:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:22:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:22:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6569348472465633, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_258_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.9101452421210734, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810458dd10>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d654d0>]}, optimizer_kwargs={'weight_decay': 5.871139055615745e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007332989259752305, 'pct_start': 0.25, 'div_factor': 45, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:22:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:22:53 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:22:53 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:22:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:22:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:22:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:22:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:22:53 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:22:53 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_258_window_0/hparams.yaml
2025-04-02 18:23:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:23:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:23:24 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:23:24 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:23:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296055
2025-04-02 18:23:27 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:23:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:23:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:23:27 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:23:27 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:23:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.315715
2025-04-02 18:23:30 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:23:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:23:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:23:30 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:23:30 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:23:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.339317
2025-04-02 18:23:33 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:23:33 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:23:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:23:33 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:23:33 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=32, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6289180168471731, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_259_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 94.09359278489063, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810478ac50>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fedd8310>]}, optimizer_kwargs={'weight_decay': 5.6044169543011975e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008556391763358056, 'pct_start': 0.25, 'div_factor': 30, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:23:33 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:23:33 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:23:34 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:23:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:23:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:23:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:23:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:23:34 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 361 K  | train
10 | temporal_decoder      | _ResidualBlock   | 17.4 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
25.0 M    Trainable params
0         Non-trainable params
25.0 M    Total params
100.008   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:23:34 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_259_window_0/hparams.yaml
2025-04-02 18:24:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:24:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:24:09 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:24:09 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:24:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.314396
2025-04-02 18:24:12 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:24:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:24:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:24:12 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:24:12 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:24:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.323066
2025-04-02 18:24:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:24:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:24:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:24:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:24:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:24:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.346165
2025-04-02 18:24:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:24:18 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:24:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:24:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:24:18 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=64, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6692471017173525, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_260_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.8019360774862906, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810390f1d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103ccfd50>]}, optimizer_kwargs={'weight_decay': 0.02158502667659427}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009957189518116157, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:24:18 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:24:18 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:24:18 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:24:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:24:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:24:18 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:24:18 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:24:18 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 164 K  | train
10 | temporal_decoder      | _ResidualBlock   | 27.5 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
48.182    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:24:18 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_260_window_0/hparams.yaml
2025-04-02 18:25:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.308246
2025-04-02 18:25:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:25:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.322606
2025-04-02 18:25:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:25:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:10 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:10 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.350344
2025-04-02 18:25:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:25:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:25:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:25:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:25:14 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6830572571241252, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_261_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6938507891388874, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fee197d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104735a50>]}, optimizer_kwargs={'weight_decay': 7.112885897957044e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009936412727365002, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:25:14 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:25:14 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:25:14 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:25:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:14 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:25:14 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_261_window_0/hparams.yaml
2025-04-02 18:25:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.292652
2025-04-02 18:25:52 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:25:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:52 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:52 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310271
2025-04-02 18:25:54 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:25:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:54 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:54 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:57 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.337977
2025-04-02 18:25:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:25:58 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:25:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:25:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:25:58 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6846805562683219, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_262_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6804596355524632, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8104257690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8104255d10>]}, optimizer_kwargs={'weight_decay': 7.614921259339896e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0009988477089498547, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 18:25:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:25:58 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:25:58 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:25:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:25:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:25:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:25:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:25:58 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:25:58 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_262_window_0/hparams.yaml
2025-04-02 18:26:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:26:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:26:34 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:26:34 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:26:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.291248
2025-04-02 18:26:37 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:26:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:26:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:26:37 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:26:37 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:26:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.310093
2025-04-02 18:26:40 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:26:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:26:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:26:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:26:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:26:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.338724
2025-04-02 18:26:43 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:26:43 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:26:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:26:43 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:26:43 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=1, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6869634434399696, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_263_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6079127616387295, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810434d550>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f810434c750>]}, optimizer_kwargs={'weight_decay': 8.678972634595388e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.000744213995019038, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': False})
2025-04-02 18:26:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:26:43 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:26:44 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:26:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:26:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:26:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:26:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:26:44 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 23.0 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
23.4 M    Trainable params
0         Non-trainable params
23.4 M    Total params
93.479    Total estimated model params size (MB)
49        Modules in train mode
0         Modules in eval mode
2025-04-02 18:26:44 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_263_window_0/hparams.yaml
2025-04-02 18:27:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:27:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:27:40 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:27:40 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:27:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.32588
2025-04-02 18:27:43 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:27:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:27:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:27:43 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:27:43 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:27:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.335563
2025-04-02 18:27:46 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:27:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:27:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:27:46 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:27:46 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:27:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.363513
2025-04-02 18:27:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:27:49 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:27:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:27:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:27:49 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6997287501088671, use_static_covariates=True, output_chunk_length=3, input_chunk_length=9, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_264_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6872463286458195, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80fed33690>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103b18b10>]}, optimizer_kwargs={'weight_decay': 7.50503281375446e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2101, 'max_lr': 0.000851134557566749, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 18:27:49 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:27:49 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 24 samples.
2025-04-02 18:27:49 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:27:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:27:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:27:49 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:27:49 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:27:49 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 26.5 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 30     | train
--------------------------------------------------------------------
26.8 M    Trainable params
0         Non-trainable params
26.8 M    Total params
107.360   Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:27:49 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_264_window_0/hparams.yaml
2025-04-02 18:28:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:28:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:28:20 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:28:20 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:28:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.426897
2025-04-02 18:28:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:28:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:28:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:28:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:28:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:28:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.408805
2025-04-02 18:28:26 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:28:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:28:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:28:26 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:28:26 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:28:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.414174
2025-04-02 18:28:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:28:29 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:28:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:28:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:28:29 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6824290941304911, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_265_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6983121693316211, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103dd17d0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fef89650>]}, optimizer_kwargs={'weight_decay': 9.980548959395531e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0006110889130071264, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 75, 'three_phase': True})
2025-04-02 18:28:29 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:28:29 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:28:29 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:28:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:28:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:28:29 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:28:29 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:28:30 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:28:30 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_265_window_0/hparams.yaml
2025-04-02 18:29:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.300513
2025-04-02 18:29:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:29:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.319086
2025-04-02 18:29:07 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:29:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:07 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:07 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:10 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.341544
2025-04-02 18:29:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:29:11 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:29:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:29:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:29:11 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6551774055849039, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_266_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.6120212635484332, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f810401ac90>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103a88810>]}, optimizer_kwargs={'weight_decay': 6.947013648499107e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0007421588274059351, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:29:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:29:11 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:29:11 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:29:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:11 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:11 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:11 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:29:11 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_266_window_0/hparams.yaml
2025-04-02 18:29:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:44 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:44 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.296525
2025-04-02 18:29:47 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:29:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:47 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:47 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.31294
2025-04-02 18:29:50 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:29:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:50 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:50 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.337243
2025-04-02 18:29:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:29:53 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:29:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:29:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:29:53 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=256, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6821836745274029, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_267_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=8, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.7576737083773677, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f8103a90410>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f80fee8a590>]}, optimizer_kwargs={'weight_decay': 8.190784997778945e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 1501, 'max_lr': 0.0008563730736329356, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:29:53 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:29:53 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:29:53 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:29:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:29:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:29:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:29:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:29:53 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 2.6 K  | train
7  | future_cov_projection | _ResidualBlock   | 2.6 K  | train
8  | encoders              | Sequential       | 11.8 M | train
9  | decoders              | Sequential       | 90.6 K | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
12.0 M    Trainable params
0         Non-trainable params
12.0 M    Total params
47.824    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:29:53 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_267_window_0/hparams.yaml
2025-04-02 18:30:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:30:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:30:14 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:30:14 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:30:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.311002
2025-04-02 18:30:17 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:30:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:30:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:30:17 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:30:17 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:30:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.319021
2025-04-02 18:30:19 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:30:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:30:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:30:19 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:30:19 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:30:22 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.331185
2025-04-02 18:30:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:30:23 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:30:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: optuna selected. Retraining frequency: False
2025-04-02 18:30:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:30:23 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.0652057978085322, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_268_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 0.5415884247850458, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81039d5490>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103d2d110>]}, optimizer_kwargs={'weight_decay': 6.677819024909255e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 2701, 'max_lr': 0.0008697172444841884, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 250, 'three_phase': True})
2025-04-02 18:30:23 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:30:23 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 30 samples.
2025-04-02 18:30:23 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:30:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:30:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:30:23 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:30:23 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:30:23 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:30:23 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/optuna/TiDE_multivariate_utc_20250402_1530/trial_268_window_0/hparams.yaml
2025-04-02 18:31:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:02 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:02 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:31:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.305552
2025-04-02 18:31:05 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:31:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:05 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:05 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:31:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.316005
2025-04-02 18:31:08 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:31:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:08 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:08 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:31:11 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.358795
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - >>>> Optuna study results
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Study name: TiDE_multivariate_utc_20250402_1530
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Number of completed trials: 269
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Best value Mean WAPE: 0.313300, WAPE by window: [0.292145, 0.309035, 0.338719] 
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Top 3 Trials:
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Rank 0: - trial#222 - Duration: 0.01 hours (0.71 minutes)
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Mean WAPE across windows: 0.313300 | WAPE by window: [0.292145, 0.309035, 0.338719]
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Rank 1: - trial#262 - Duration: 0.01 hours (0.76 minutes)
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Mean WAPE across windows: 0.313355 | WAPE by window: [0.292145, 0.309035, 0.338719]
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Rank 2: - trial#212 - Duration: 0.01 hours (0.66 minutes)
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - INFO - Mean WAPE across windows: 0.313441 | WAPE by window: [0.292145, 0.309035, 0.338719]
2025-04-02 18:31:11 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - Best Trial Parameters values and importance of parameter for the study:
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - input_chunk_length: 3   (Importance: 0.87667)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - max_lr: 0.0009968937728218627   (Importance: 0.07680)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - three_phase: True   (Importance: 0.01355)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - batch_size: 4   (Importance: 0.00796)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - decoder_output_dim: 16   (Importance: 0.00688)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - temporal_decoder_hidden: 16   (Importance: 0.00417)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - num_encoder_layers: 3   (Importance: 0.00245)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - div_factor: 50   (Importance: 0.00235)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - final_div_factor: 100   (Importance: 0.00235)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - dropout: 0.6722075581262937   (Importance: 0.00191)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - gradient_clip_val: 1.1749532965638991   (Importance: 0.00179)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - num_decoder_layers: 1   (Importance: 0.00167)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - pct_start: 0.25   (Importance: 0.00083)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - hidden_size: 512   (Importance: 0.00053)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - log_optuna_results - DEBUG - weight_decay: 6.917377014011272e-05   (Importance: 0.00008)
2025-04-02 18:31:14 UTC - src.pipelines.dl_optuna - execute_optuna_study - INFO - Optuna optimization completed successfully in 3.0 hours (180.2 minutes)
2025-04-02 18:31:14 UTC - src.pipelines.dl_backtest - execute_backtest - INFO - >>>>>>> Starting backtest execution
2025-04-02 18:31:14 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - DEBUG - Preparing model parameters...
2025-04-02 18:31:15 UTC - src.utilities.dl_model_param_setup - retrieve_optuna_best_parameters - DEBUG - 
Selected trial from study 'TiDE_multivariate_utc_20250402_1530' with direction minimize and value: 0.31330
Parameters from best trial: 
{'batch_size': 4,
 'decoder_output_dim': 16,
 'div_factor': 50,
 'dropout': 0.6722075581262937,
 'final_div_factor': 100,
 'gradient_clip_val': 1.1749532965638991,
 'hidden_size': 512,
 'input_chunk_length': 3,
 'max_lr': 0.0009968937728218627,
 'num_decoder_layers': 1,
 'num_encoder_layers': 3,
 'pct_start': 0.25,
 'temporal_decoder_hidden': 16,
 'three_phase': True,
 'weight_decay': 6.917377014011272e-05}
2025-04-02 18:31:15 UTC - src.utilities.dl_model_param_setup - setup_model_parameters - INFO - Model parameters setup completed.
2025-04-02 18:31:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - DEBUG - Mode: backtest selected. Retraining frequency: 3
2025-04-02 18:31:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 0.
2025-04-02 18:31:15 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6722075581262937, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/backtest/TiDE_multivariate_utc_20250402_1530/backtest_window_0, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1749532965638991, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f81040b8dd0>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8103a93ed0>]}, optimizer_kwargs={'weight_decay': 6.917377014011272e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 3001, 'max_lr': 0.0009968937728218627, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:31:15 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 0
2025-04-02 18:31:15 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 36 samples.
2025-04-02 18:31:15 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:31:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:15 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:15 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:31:15 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:31:15 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/backtest/TiDE_multivariate_utc_20250402_1530/backtest_window_0/hparams.yaml
2025-04-02 18:31:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:53 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:53 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:31:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 0 with mean WAPE: 0.47739
2025-04-02 18:31:55 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 1
2025-04-02 18:31:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:55 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:55 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:31:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 1 with mean WAPE: 0.421037
2025-04-02 18:31:58 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 2
2025-04-02 18:31:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:31:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:31:58 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:31:58 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:32:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 2 with mean WAPE: 0.373172
2025-04-02 18:32:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model initialized for training in window 3.
2025-04-02 18:32:01 UTC - src.pipelines.dl_backtest - initialize_model_for_training - DEBUG - Model parameters: 
TiDEModel(output_chunk_shift=1, num_encoder_layers=3, num_decoder_layers=1, decoder_output_dim=16, hidden_size=512, temporal_width_past=4, temporal_width_future=4, temporal_hidden_size_past=None, temporal_hidden_size_future=None, temporal_decoder_hidden=16, use_layer_norm=True, dropout=0.6722075581262937, use_static_covariates=True, output_chunk_length=3, input_chunk_length=3, random_state=1000, force_reset=True, work_dir=/workspace/logs/tensorboard_logs/backtest/TiDE_multivariate_utc_20250402_1530/backtest_window_3, use_reversible_instance_norm=True, optimizer_cls=<class 'torch.optim.adamw.AdamW'>, n_epochs=300, batch_size=4, pl_trainer_kwargs={'accelerator': 'gpu', 'devices': 1, 'enable_progress_bar': True, 'enable_model_summary': True, 'enable_checkpointing': False, 'check_val_every_n_epoch': 1, 'log_every_n_steps': 10, 'gradient_clip_algorithm': 'norm', 'gradient_clip_val': 1.1749532965638991, 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x7f80febf9350>, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7f8101196510>]}, optimizer_kwargs={'weight_decay': 6.917377014011272e-05}, lr_scheduler_cls=<class 'torch.optim.lr_scheduler.OneCycleLR'>, lr_scheduler_kwargs={'interval': 'step', 'frequency': 1, 'total_steps': 3301, 'max_lr': 0.0009968937728218627, 'pct_start': 0.25, 'div_factor': 50, 'final_div_factor': 100, 'three_phase': True})
2025-04-02 18:32:01 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 3
2025-04-02 18:32:01 UTC - darts.models.forecasting.torch_forecasting_model - _setup_for_fit_from_dataset - INFO - Train dataset contains 39 samples.
2025-04-02 18:32:01 UTC - darts.models.forecasting.torch_forecasting_model - _init_model - INFO - Time series values are 32-bits; casting model to float32.
2025-04-02 18:32:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:32:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:32:01 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:32:01 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:32:01 UTC - pytorch_lightning.callbacks.model_summary - summarize - INFO - 
   | Name                  | Type             | Params | Mode 
--------------------------------------------------------------------
0  | criterion             | MSELoss          | 0      | train
1  | train_criterion       | MSELoss          | 0      | train
2  | val_criterion         | MSELoss          | 0      | train
3  | train_metrics         | MetricCollection | 0      | train
4  | val_metrics           | MetricCollection | 0      | train
5  | rin                   | RINorm           | 600    | train
6  | past_cov_projection   | _ResidualBlock   | 5.2 K  | train
7  | future_cov_projection | _ResidualBlock   | 5.2 K  | train
8  | encoders              | Sequential       | 24.6 M | train
9  | decoders              | Sequential       | 312 K  | train
10 | temporal_decoder      | _ResidualBlock   | 12.3 K | train
11 | lookback_skip         | Linear           | 12     | train
--------------------------------------------------------------------
24.9 M    Trainable params
0         Non-trainable params
24.9 M    Total params
99.790    Total estimated model params size (MB)
65        Modules in train mode
0         Modules in eval mode
2025-04-02 18:32:01 UTC - fsspec.local - __init__ - DEBUG - open file: /workspace/logs/tensorboard_logs/backtest/TiDE_multivariate_utc_20250402_1530/backtest_window_3/hparams.yaml
2025-04-02 18:32:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:32:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:32:36 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:32:36 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:32:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 3 with mean WAPE: 0.331155
2025-04-02 18:32:39 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 4
2025-04-02 18:32:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:32:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:32:39 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:32:39 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:32:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 4 with mean WAPE: 0.311991
2025-04-02 18:32:42 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Running model pipeline for window 5
2025-04-02 18:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - GPU available: True (cuda), used: True
2025-04-02 18:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - TPU available: False, using: 0 TPU cores
2025-04-02 18:32:42 UTC - pytorch_lightning.utilities.rank_zero - _log_device_info - INFO - HPU available: False, using: 0 HPUs
2025-04-02 18:32:42 UTC - pytorch_lightning.accelerators.cuda - set_nvidia_flags - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-04-02 18:32:45 UTC - src.pipelines.dl_backtest - run_dl_models_across_windows - INFO - Completed window 5 with mean WAPE: 0.339149
2025-04-02 18:32:45 UTC - src.utilities.general_utils - save_backtest_results - INFO - Results saved to: /workspace/data/backtest_results/TiDE_multivariate_backtest_utc_20250402_1530_window_results.csv
2025-04-02 18:32:45 UTC - src.utilities.general_utils - save_backtest_results - INFO - Results saved to: /workspace/data/backtest_results/TiDE_multivariate_backtest_utc_20250402_1530_series_results.csv
2025-04-02 18:32:45 UTC - src.pipelines.dl_backtest - execute_backtest - INFO - Backtest completed successfully in 0.0 hours (1.5 minutes)
2025-04-02 18:32:45 UTC - src.utilities.general_utils - cleanup - DEBUG - Performing cleanup operations
2025-04-02 18:32:45 UTC - src.pipelines.dl_full_pipeline - execute_deep_learning_pipeline - INFO - Deep learning pipeline completed in 3.0 hours (181.8 minutes)
2025-04-02 18:32:45 UTC - src.pipelines.dl_full_pipeline - main - INFO - Deep learning Pipeline execution completed successfully
